{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from dqn_agent import *\n",
    "from environment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 7,559\n",
      "Trainable params: 7,559\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 7,559\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,559\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "env = GameEnv()\n",
    "observation_space = env.reset()\n",
    "\n",
    "agent = DoubleDQNAgentWithExplorationAndReplay(observation_space.shape, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1 agent1 cumulative reward:  76 epsilon: 0.9995499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 2 agent1 cumulative reward:  60 epsilon: 0.9986499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 3 agent1 cumulative reward:  49 epsilon: 0.99775 step 1000 learning rate: 0.00025\n",
      "episode: 4 agent1 cumulative reward:  73 epsilon: 0.99685 step 1000 learning rate: 0.00025\n",
      "episode: 5 agent1 cumulative reward:  69 epsilon: 0.99595 step 1000 learning rate: 0.00025\n",
      "episode: 6 agent1 cumulative reward:  30 epsilon: 0.99505 step 1000 learning rate: 0.00025\n",
      "episode: 7 agent1 cumulative reward:  70 epsilon: 0.99415 step 1000 learning rate: 0.00025\n",
      "episode: 8 agent1 cumulative reward:  29 epsilon: 0.99325 step 1000 learning rate: 0.00025\n",
      "episode: 9 agent1 cumulative reward:  46 epsilon: 0.99235 step 1000 learning rate: 0.00025\n",
      "episode: 10 agent1 cumulative reward:  65 epsilon: 0.9914499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 11 agent1 cumulative reward:  39 epsilon: 0.9905499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 12 agent1 cumulative reward:  57 epsilon: 0.98965 step 1000 learning rate: 0.00025\n",
      "episode: 13 agent1 cumulative reward:  54 epsilon: 0.98875 step 1000 learning rate: 0.00025\n",
      "episode: 14 agent1 cumulative reward:  59 epsilon: 0.98785 step 1000 learning rate: 0.00025\n",
      "episode: 15 agent1 cumulative reward:  66 epsilon: 0.98695 step 1000 learning rate: 0.00025\n",
      "episode: 16 agent1 cumulative reward:  38 epsilon: 0.98605 step 1000 learning rate: 0.00025\n",
      "episode: 17 agent1 cumulative reward:  47 epsilon: 0.98515 step 1000 learning rate: 0.00025\n",
      "episode: 18 agent1 cumulative reward:  81 epsilon: 0.98425 step 1000 learning rate: 0.00025\n",
      "episode: 19 agent1 cumulative reward:  27 epsilon: 0.98335 step 1000 learning rate: 0.00025\n",
      "episode: 20 agent1 cumulative reward:  66 epsilon: 0.9824499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 21 agent1 cumulative reward:  51 epsilon: 0.9815499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 22 agent1 cumulative reward:  68 epsilon: 0.98065 step 1000 learning rate: 0.00025\n",
      "episode: 23 agent1 cumulative reward:  31 epsilon: 0.97975 step 1000 learning rate: 0.00025\n",
      "episode: 24 agent1 cumulative reward:  76 epsilon: 0.97885 step 1000 learning rate: 0.00025\n",
      "episode: 25 agent1 cumulative reward:  73 epsilon: 0.97795 step 1000 learning rate: 0.00025\n",
      "episode: 26 agent1 cumulative reward:  53 epsilon: 0.97705 step 1000 learning rate: 0.00025\n",
      "episode: 27 agent1 cumulative reward:  53 epsilon: 0.97615 step 1000 learning rate: 0.00025\n",
      "episode: 28 agent1 cumulative reward:  64 epsilon: 0.97525 step 1000 learning rate: 0.00025\n",
      "episode: 29 agent1 cumulative reward:  36 epsilon: 0.9743499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 30 agent1 cumulative reward:  70 epsilon: 0.9734499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 31 agent1 cumulative reward:  44 epsilon: 0.97255 step 1000 learning rate: 0.00025\n",
      "episode: 32 agent1 cumulative reward:  73 epsilon: 0.97165 step 1000 learning rate: 0.00025\n",
      "episode: 33 agent1 cumulative reward:  44 epsilon: 0.97075 step 1000 learning rate: 0.00025\n",
      "episode: 34 agent1 cumulative reward:  67 epsilon: 0.96985 step 1000 learning rate: 0.00025\n",
      "episode: 35 agent1 cumulative reward:  81 epsilon: 0.96895 step 1000 learning rate: 0.00025\n",
      "episode: 36 agent1 cumulative reward:  53 epsilon: 0.96805 step 1000 learning rate: 0.00025\n",
      "episode: 37 agent1 cumulative reward:  47 epsilon: 0.96715 step 1000 learning rate: 0.00025\n",
      "episode: 38 agent1 cumulative reward:  80 epsilon: 0.9662499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 39 agent1 cumulative reward:  67 epsilon: 0.9653499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 40 agent1 cumulative reward:  41 epsilon: 0.96445 step 1000 learning rate: 0.00025\n",
      "episode: 41 agent1 cumulative reward:  82 epsilon: 0.96355 step 1000 learning rate: 0.00025\n",
      "episode: 42 agent1 cumulative reward:  46 epsilon: 0.96265 step 1000 learning rate: 0.00025\n",
      "episode: 43 agent1 cumulative reward:  73 epsilon: 0.96175 step 1000 learning rate: 0.00025\n",
      "episode: 44 agent1 cumulative reward:  59 epsilon: 0.96085 step 1000 learning rate: 0.00025\n",
      "episode: 45 agent1 cumulative reward:  47 epsilon: 0.95995 step 1000 learning rate: 0.00025\n",
      "episode: 46 agent1 cumulative reward:  39 epsilon: 0.95905 step 1000 learning rate: 0.00025\n",
      "episode: 47 agent1 cumulative reward:  74 epsilon: 0.95815 step 1000 learning rate: 0.00025\n",
      "episode: 48 agent1 cumulative reward:  72 epsilon: 0.9572499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 49 agent1 cumulative reward:  81 epsilon: 0.9563499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 50 agent1 cumulative reward:  56 epsilon: 0.95545 step 1000 learning rate: 0.00025\n",
      "episode: 51 agent1 cumulative reward:  54 epsilon: 0.95455 step 1000 learning rate: 0.00025\n",
      "episode: 52 agent1 cumulative reward:  64 epsilon: 0.95365 step 1000 learning rate: 0.00025\n",
      "episode: 53 agent1 cumulative reward:  67 epsilon: 0.95275 step 1000 learning rate: 0.00025\n",
      "episode: 54 agent1 cumulative reward:  63 epsilon: 0.95185 step 1000 learning rate: 0.00025\n",
      "episode: 55 agent1 cumulative reward:  77 epsilon: 0.95095 step 1000 learning rate: 0.00025\n",
      "episode: 56 agent1 cumulative reward:  68 epsilon: 0.95005 step 1000 learning rate: 0.00025\n",
      "episode: 57 agent1 cumulative reward:  84 epsilon: 0.9491499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 58 agent1 cumulative reward:  59 epsilon: 0.9482499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 59 agent1 cumulative reward:  76 epsilon: 0.94735 step 1000 learning rate: 0.00025\n",
      "episode: 60 agent1 cumulative reward:  68 epsilon: 0.94645 step 1000 learning rate: 0.00025\n",
      "episode: 61 agent1 cumulative reward:  57 epsilon: 0.94555 step 1000 learning rate: 0.00025\n",
      "episode: 62 agent1 cumulative reward:  64 epsilon: 0.94465 step 1000 learning rate: 0.00025\n",
      "episode: 63 agent1 cumulative reward:  57 epsilon: 0.94375 step 1000 learning rate: 0.00025\n",
      "episode: 64 agent1 cumulative reward:  57 epsilon: 0.94285 step 1000 learning rate: 0.00025\n",
      "episode: 65 agent1 cumulative reward:  74 epsilon: 0.94195 step 1000 learning rate: 0.00025\n",
      "episode: 66 agent1 cumulative reward:  56 epsilon: 0.9410499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 67 agent1 cumulative reward:  67 epsilon: 0.9401499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 68 agent1 cumulative reward:  88 epsilon: 0.93925 step 1000 learning rate: 0.00025\n",
      "episode: 69 agent1 cumulative reward:  64 epsilon: 0.93835 step 1000 learning rate: 0.00025\n",
      "episode: 70 agent1 cumulative reward:  94 epsilon: 0.93745 step 1000 learning rate: 0.00025\n",
      "episode: 71 agent1 cumulative reward:  72 epsilon: 0.93655 step 1000 learning rate: 0.00025\n",
      "episode: 72 agent1 cumulative reward:  81 epsilon: 0.93565 step 1000 learning rate: 0.00025\n",
      "episode: 73 agent1 cumulative reward:  31 epsilon: 0.93475 step 1000 learning rate: 0.00025\n",
      "episode: 74 agent1 cumulative reward:  83 epsilon: 0.93385 step 1000 learning rate: 0.00025\n",
      "episode: 75 agent1 cumulative reward:  85 epsilon: 0.93295 step 1000 learning rate: 0.00025\n",
      "episode: 76 agent1 cumulative reward:  63 epsilon: 0.9320499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 77 agent1 cumulative reward:  75 epsilon: 0.93115 step 1000 learning rate: 0.00025\n",
      "episode: 78 agent1 cumulative reward:  81 epsilon: 0.93025 step 1000 learning rate: 0.00025\n",
      "episode: 79 agent1 cumulative reward:  69 epsilon: 0.92935 step 1000 learning rate: 0.00025\n",
      "episode: 80 agent1 cumulative reward:  42 epsilon: 0.92845 step 1000 learning rate: 0.00025\n",
      "episode: 81 agent1 cumulative reward:  70 epsilon: 0.92755 step 1000 learning rate: 0.00025\n",
      "episode: 82 agent1 cumulative reward:  58 epsilon: 0.92665 step 1000 learning rate: 0.00025\n",
      "episode: 83 agent1 cumulative reward:  75 epsilon: 0.92575 step 1000 learning rate: 0.00025\n",
      "episode: 84 agent1 cumulative reward:  106 epsilon: 0.92485 step 1000 learning rate: 0.00025\n",
      "episode: 85 agent1 cumulative reward:  85 epsilon: 0.9239499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 86 agent1 cumulative reward:  54 epsilon: 0.9230499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 87 agent1 cumulative reward:  87 epsilon: 0.92215 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 88 agent1 cumulative reward:  59 epsilon: 0.92125 step 1000 learning rate: 0.00025\n",
      "episode: 89 agent1 cumulative reward:  69 epsilon: 0.92035 step 1000 learning rate: 0.00025\n",
      "episode: 90 agent1 cumulative reward:  76 epsilon: 0.91945 step 1000 learning rate: 0.00025\n",
      "episode: 91 agent1 cumulative reward:  77 epsilon: 0.91855 step 1000 learning rate: 0.00025\n",
      "episode: 92 agent1 cumulative reward:  78 epsilon: 0.91765 step 1000 learning rate: 0.00025\n",
      "episode: 93 agent1 cumulative reward:  79 epsilon: 0.91675 step 1000 learning rate: 0.00025\n",
      "episode: 94 agent1 cumulative reward:  77 epsilon: 0.9158499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 95 agent1 cumulative reward:  80 epsilon: 0.9149499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 96 agent1 cumulative reward:  81 epsilon: 0.91405 step 1000 learning rate: 0.00025\n",
      "episode: 97 agent1 cumulative reward:  69 epsilon: 0.91315 step 1000 learning rate: 0.00025\n",
      "episode: 98 agent1 cumulative reward:  86 epsilon: 0.91225 step 1000 learning rate: 0.00025\n",
      "episode: 99 agent1 cumulative reward:  64 epsilon: 0.91135 step 1000 learning rate: 0.00025\n",
      "episode: 100 agent1 cumulative reward:  115 epsilon: 0.91045 step 1000 learning rate: 0.00025\n",
      "episode: 101 agent1 cumulative reward:  83 epsilon: 0.90955 step 1000 learning rate: 0.00025\n",
      "episode: 102 agent1 cumulative reward:  83 epsilon: 0.90865 step 1000 learning rate: 0.00025\n",
      "episode: 103 agent1 cumulative reward:  76 epsilon: 0.90775 step 1000 learning rate: 0.00025\n",
      "episode: 104 agent1 cumulative reward:  69 epsilon: 0.9068499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 105 agent1 cumulative reward:  90 epsilon: 0.90595 step 1000 learning rate: 0.00025\n",
      "episode: 106 agent1 cumulative reward:  61 epsilon: 0.90505 step 1000 learning rate: 0.00025\n",
      "episode: 107 agent1 cumulative reward:  74 epsilon: 0.90415 step 1000 learning rate: 0.00025\n",
      "episode: 108 agent1 cumulative reward:  77 epsilon: 0.90325 step 1000 learning rate: 0.00025\n",
      "episode: 109 agent1 cumulative reward:  57 epsilon: 0.90235 step 1000 learning rate: 0.00025\n",
      "episode: 110 agent1 cumulative reward:  86 epsilon: 0.90145 step 1000 learning rate: 0.00025\n",
      "episode: 111 agent1 cumulative reward:  62 epsilon: 0.90055 step 1000 learning rate: 0.00025\n",
      "episode: 112 agent1 cumulative reward:  65 epsilon: 0.89965 step 1000 learning rate: 0.00025\n",
      "episode: 113 agent1 cumulative reward:  57 epsilon: 0.8987499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 114 agent1 cumulative reward:  95 epsilon: 0.8978499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 115 agent1 cumulative reward:  88 epsilon: 0.89695 step 1000 learning rate: 0.00025\n",
      "episode: 116 agent1 cumulative reward:  88 epsilon: 0.89605 step 1000 learning rate: 0.00025\n",
      "episode: 117 agent1 cumulative reward:  83 epsilon: 0.89515 step 1000 learning rate: 0.00025\n",
      "episode: 118 agent1 cumulative reward:  79 epsilon: 0.89425 step 1000 learning rate: 0.00025\n",
      "episode: 119 agent1 cumulative reward:  93 epsilon: 0.89335 step 1000 learning rate: 0.00025\n",
      "episode: 120 agent1 cumulative reward:  84 epsilon: 0.89245 step 1000 learning rate: 0.00025\n",
      "episode: 121 agent1 cumulative reward:  75 epsilon: 0.89155 step 1000 learning rate: 0.00025\n",
      "episode: 122 agent1 cumulative reward:  92 epsilon: 0.8906499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 123 agent1 cumulative reward:  72 epsilon: 0.8897499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 124 agent1 cumulative reward:  46 epsilon: 0.88885 step 1000 learning rate: 0.00025\n",
      "episode: 125 agent1 cumulative reward:  71 epsilon: 0.88795 step 1000 learning rate: 0.00025\n",
      "episode: 126 agent1 cumulative reward:  63 epsilon: 0.88705 step 1000 learning rate: 0.00025\n",
      "episode: 127 agent1 cumulative reward:  72 epsilon: 0.88615 step 1000 learning rate: 0.00025\n",
      "episode: 128 agent1 cumulative reward:  83 epsilon: 0.88525 step 1000 learning rate: 0.00025\n",
      "episode: 129 agent1 cumulative reward:  76 epsilon: 0.88435 step 1000 learning rate: 0.00025\n",
      "episode: 130 agent1 cumulative reward:  26 epsilon: 0.88345 step 1000 learning rate: 0.00025\n",
      "episode: 131 agent1 cumulative reward:  82 epsilon: 0.88255 step 1000 learning rate: 0.00025\n",
      "episode: 132 agent1 cumulative reward:  82 epsilon: 0.8816499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 133 agent1 cumulative reward:  94 epsilon: 0.88075 step 1000 learning rate: 0.00025\n",
      "episode: 134 agent1 cumulative reward:  83 epsilon: 0.87985 step 1000 learning rate: 0.00025\n",
      "episode: 135 agent1 cumulative reward:  104 epsilon: 0.87895 step 1000 learning rate: 0.00025\n",
      "episode: 136 agent1 cumulative reward:  83 epsilon: 0.87805 step 1000 learning rate: 0.00025\n",
      "episode: 137 agent1 cumulative reward:  92 epsilon: 0.87715 step 1000 learning rate: 0.00025\n",
      "episode: 138 agent1 cumulative reward:  68 epsilon: 0.87625 step 1000 learning rate: 0.00025\n",
      "episode: 139 agent1 cumulative reward:  72 epsilon: 0.87535 step 1000 learning rate: 0.00025\n",
      "episode: 140 agent1 cumulative reward:  86 epsilon: 0.87445 step 1000 learning rate: 0.00025\n",
      "episode: 141 agent1 cumulative reward:  62 epsilon: 0.8735499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 142 agent1 cumulative reward:  83 epsilon: 0.8726499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 143 agent1 cumulative reward:  73 epsilon: 0.87175 step 1000 learning rate: 0.00025\n",
      "episode: 144 agent1 cumulative reward:  98 epsilon: 0.87085 step 1000 learning rate: 0.00025\n",
      "episode: 145 agent1 cumulative reward:  79 epsilon: 0.86995 step 1000 learning rate: 0.00025\n",
      "episode: 146 agent1 cumulative reward:  95 epsilon: 0.86905 step 1000 learning rate: 0.00025\n",
      "episode: 147 agent1 cumulative reward:  106 epsilon: 0.86815 step 1000 learning rate: 0.00025\n",
      "episode: 148 agent1 cumulative reward:  93 epsilon: 0.86725 step 1000 learning rate: 0.00025\n",
      "episode: 149 agent1 cumulative reward:  73 epsilon: 0.86635 step 1000 learning rate: 0.00025\n",
      "episode: 150 agent1 cumulative reward:  107 epsilon: 0.8654499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 151 agent1 cumulative reward:  114 epsilon: 0.8645499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 152 agent1 cumulative reward:  45 epsilon: 0.86365 step 1000 learning rate: 0.00025\n",
      "episode: 153 agent1 cumulative reward:  98 epsilon: 0.86275 step 1000 learning rate: 0.00025\n",
      "episode: 154 agent1 cumulative reward:  87 epsilon: 0.86185 step 1000 learning rate: 0.00025\n",
      "episode: 155 agent1 cumulative reward:  72 epsilon: 0.86095 step 1000 learning rate: 0.00025\n",
      "episode: 156 agent1 cumulative reward:  77 epsilon: 0.86005 step 1000 learning rate: 0.00025\n",
      "episode: 157 agent1 cumulative reward:  82 epsilon: 0.85915 step 1000 learning rate: 0.00025\n",
      "episode: 158 agent1 cumulative reward:  82 epsilon: 0.85825 step 1000 learning rate: 0.00025\n",
      "episode: 159 agent1 cumulative reward:  106 epsilon: 0.85735 step 1000 learning rate: 0.00025\n",
      "episode: 160 agent1 cumulative reward:  80 epsilon: 0.8564499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 161 agent1 cumulative reward:  121 epsilon: 0.85555 step 1000 learning rate: 0.00025\n",
      "episode: 162 agent1 cumulative reward:  84 epsilon: 0.85465 step 1000 learning rate: 0.00025\n",
      "episode: 163 agent1 cumulative reward:  96 epsilon: 0.85375 step 1000 learning rate: 0.00025\n",
      "episode: 164 agent1 cumulative reward:  67 epsilon: 0.85285 step 1000 learning rate: 0.00025\n",
      "episode: 165 agent1 cumulative reward:  83 epsilon: 0.85195 step 1000 learning rate: 0.00025\n",
      "episode: 166 agent1 cumulative reward:  85 epsilon: 0.85105 step 1000 learning rate: 0.00025\n",
      "episode: 167 agent1 cumulative reward:  84 epsilon: 0.85015 step 1000 learning rate: 0.00025\n",
      "episode: 168 agent1 cumulative reward:  74 epsilon: 0.84925 step 1000 learning rate: 0.00025\n",
      "episode: 169 agent1 cumulative reward:  84 epsilon: 0.8483499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 170 agent1 cumulative reward:  69 epsilon: 0.8474499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 171 agent1 cumulative reward:  77 epsilon: 0.84655 step 1000 learning rate: 0.00025\n",
      "episode: 172 agent1 cumulative reward:  60 epsilon: 0.84565 step 1000 learning rate: 0.00025\n",
      "episode: 173 agent1 cumulative reward:  94 epsilon: 0.84475 step 1000 learning rate: 0.00025\n",
      "episode: 174 agent1 cumulative reward:  77 epsilon: 0.84385 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 175 agent1 cumulative reward:  64 epsilon: 0.84295 step 1000 learning rate: 0.00025\n",
      "episode: 176 agent1 cumulative reward:  85 epsilon: 0.84205 step 1000 learning rate: 0.00025\n",
      "episode: 177 agent1 cumulative reward:  95 epsilon: 0.84115 step 1000 learning rate: 0.00025\n",
      "episode: 178 agent1 cumulative reward:  60 epsilon: 0.8402499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 179 agent1 cumulative reward:  88 epsilon: 0.8393499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 180 agent1 cumulative reward:  84 epsilon: 0.83845 step 1000 learning rate: 0.00025\n",
      "episode: 181 agent1 cumulative reward:  73 epsilon: 0.83755 step 1000 learning rate: 0.00025\n",
      "episode: 182 agent1 cumulative reward:  97 epsilon: 0.83665 step 1000 learning rate: 0.00025\n",
      "episode: 183 agent1 cumulative reward:  87 epsilon: 0.83575 step 1000 learning rate: 0.00025\n",
      "episode: 184 agent1 cumulative reward:  99 epsilon: 0.83485 step 1000 learning rate: 0.00025\n",
      "episode: 185 agent1 cumulative reward:  82 epsilon: 0.83395 step 1000 learning rate: 0.00025\n",
      "episode: 186 agent1 cumulative reward:  106 epsilon: 0.83305 step 1000 learning rate: 0.00025\n",
      "episode: 187 agent1 cumulative reward:  81 epsilon: 0.83215 step 1000 learning rate: 0.00025\n",
      "episode: 188 agent1 cumulative reward:  120 epsilon: 0.8312499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 189 agent1 cumulative reward:  64 epsilon: 0.83035 step 1000 learning rate: 0.00025\n",
      "episode: 190 agent1 cumulative reward:  77 epsilon: 0.82945 step 1000 learning rate: 0.00025\n",
      "episode: 191 agent1 cumulative reward:  79 epsilon: 0.82855 step 1000 learning rate: 0.00025\n",
      "episode: 192 agent1 cumulative reward:  83 epsilon: 0.82765 step 1000 learning rate: 0.00025\n",
      "episode: 193 agent1 cumulative reward:  105 epsilon: 0.82675 step 1000 learning rate: 0.00025\n",
      "episode: 194 agent1 cumulative reward:  73 epsilon: 0.82585 step 1000 learning rate: 0.00025\n",
      "episode: 195 agent1 cumulative reward:  106 epsilon: 0.82495 step 1000 learning rate: 0.00025\n",
      "episode: 196 agent1 cumulative reward:  83 epsilon: 0.82405 step 1000 learning rate: 0.00025\n",
      "episode: 197 agent1 cumulative reward:  89 epsilon: 0.8231499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 198 agent1 cumulative reward:  79 epsilon: 0.8222499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 199 agent1 cumulative reward:  72 epsilon: 0.82135 step 1000 learning rate: 0.00025\n",
      "episode: 200 agent1 cumulative reward:  87 epsilon: 0.82045 step 1000 learning rate: 0.00025\n",
      "episode: 201 agent1 cumulative reward:  97 epsilon: 0.81955 step 1000 learning rate: 0.00025\n",
      "episode: 202 agent1 cumulative reward:  72 epsilon: 0.81865 step 1000 learning rate: 0.00025\n",
      "episode: 203 agent1 cumulative reward:  86 epsilon: 0.81775 step 1000 learning rate: 0.00025\n",
      "episode: 204 agent1 cumulative reward:  83 epsilon: 0.81685 step 1000 learning rate: 0.00025\n",
      "episode: 205 agent1 cumulative reward:  77 epsilon: 0.81595 step 1000 learning rate: 0.00025\n",
      "episode: 206 agent1 cumulative reward:  107 epsilon: 0.8150499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 207 agent1 cumulative reward:  87 epsilon: 0.8141499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 208 agent1 cumulative reward:  101 epsilon: 0.81325 step 1000 learning rate: 0.00025\n",
      "episode: 209 agent1 cumulative reward:  52 epsilon: 0.81235 step 1000 learning rate: 0.00025\n",
      "episode: 210 agent1 cumulative reward:  73 epsilon: 0.81145 step 1000 learning rate: 0.00025\n",
      "episode: 211 agent1 cumulative reward:  98 epsilon: 0.81055 step 1000 learning rate: 0.00025\n",
      "episode: 212 agent1 cumulative reward:  90 epsilon: 0.80965 step 1000 learning rate: 0.00025\n",
      "episode: 213 agent1 cumulative reward:  67 epsilon: 0.80875 step 1000 learning rate: 0.00025\n",
      "episode: 214 agent1 cumulative reward:  112 epsilon: 0.80785 step 1000 learning rate: 0.00025\n",
      "episode: 215 agent1 cumulative reward:  90 epsilon: 0.80695 step 1000 learning rate: 0.00025\n",
      "episode: 216 agent1 cumulative reward:  99 epsilon: 0.8060499999999999 step 1000 learning rate: 0.00025\n",
      "episode: 217 agent1 cumulative reward:  97 epsilon: 0.80515 step 1000 learning rate: 0.00025\n",
      "episode: 218 agent1 cumulative reward:  94 epsilon: 0.80425 step 1000 learning rate: 0.00025\n",
      "episode: 219 agent1 cumulative reward:  72 epsilon: 0.80335 step 1000 learning rate: 0.00025\n",
      "episode: 220 agent1 cumulative reward:  110 epsilon: 0.80245 step 1000 learning rate: 0.00025\n",
      "episode: 221 agent1 cumulative reward:  109 epsilon: 0.8015662 step 982 learning rate: 0.00025\n",
      "episode: 222 agent1 cumulative reward:  100 epsilon: 0.8006662 step 1000 learning rate: 0.00025\n",
      "episode: 223 agent1 cumulative reward:  87 epsilon: 0.7997662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 224 agent1 cumulative reward:  96 epsilon: 0.7988662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 225 agent1 cumulative reward:  71 epsilon: 0.7979662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 226 agent1 cumulative reward:  118 epsilon: 0.7970662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 227 agent1 cumulative reward:  103 epsilon: 0.7961662 step 1000 learning rate: 0.00025\n",
      "episode: 228 agent1 cumulative reward:  109 epsilon: 0.7952662 step 1000 learning rate: 0.00025\n",
      "episode: 229 agent1 cumulative reward:  105 epsilon: 0.7943662 step 1000 learning rate: 0.00025\n",
      "episode: 230 agent1 cumulative reward:  121 epsilon: 0.7934662 step 1000 learning rate: 0.00025\n",
      "episode: 231 agent1 cumulative reward:  72 epsilon: 0.7925662 step 1000 learning rate: 0.00025\n",
      "episode: 232 agent1 cumulative reward:  77 epsilon: 0.7916662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 233 agent1 cumulative reward:  83 epsilon: 0.7907662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 234 agent1 cumulative reward:  87 epsilon: 0.7898662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 235 agent1 cumulative reward:  84 epsilon: 0.7889662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 236 agent1 cumulative reward:  120 epsilon: 0.7880662 step 1000 learning rate: 0.00025\n",
      "episode: 237 agent1 cumulative reward:  92 epsilon: 0.7871662 step 1000 learning rate: 0.00025\n",
      "episode: 238 agent1 cumulative reward:  100 epsilon: 0.7862662 step 1000 learning rate: 0.00025\n",
      "episode: 239 agent1 cumulative reward:  105 epsilon: 0.7853662 step 1000 learning rate: 0.00025\n",
      "episode: 240 agent1 cumulative reward:  96 epsilon: 0.7844662 step 1000 learning rate: 0.00025\n",
      "episode: 241 agent1 cumulative reward:  111 epsilon: 0.7835662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 242 agent1 cumulative reward:  81 epsilon: 0.7826662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 243 agent1 cumulative reward:  113 epsilon: 0.7817662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 244 agent1 cumulative reward:  86 epsilon: 0.7808662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 245 agent1 cumulative reward:  103 epsilon: 0.7799662 step 1000 learning rate: 0.00025\n",
      "episode: 246 agent1 cumulative reward:  95 epsilon: 0.7790662 step 1000 learning rate: 0.00025\n",
      "episode: 247 agent1 cumulative reward:  130 epsilon: 0.7781662 step 1000 learning rate: 0.00025\n",
      "episode: 248 agent1 cumulative reward:  96 epsilon: 0.7772662 step 1000 learning rate: 0.00025\n",
      "episode: 249 agent1 cumulative reward:  79 epsilon: 0.7763662 step 1000 learning rate: 0.00025\n",
      "episode: 250 agent1 cumulative reward:  76 epsilon: 0.7754662 step 1000 learning rate: 0.00025\n",
      "episode: 251 agent1 cumulative reward:  111 epsilon: 0.7745662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 252 agent1 cumulative reward:  86 epsilon: 0.7736662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 253 agent1 cumulative reward:  63 epsilon: 0.7727662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 254 agent1 cumulative reward:  69 epsilon: 0.7718662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 255 agent1 cumulative reward:  103 epsilon: 0.7709662 step 1000 learning rate: 0.00025\n",
      "episode: 256 agent1 cumulative reward:  92 epsilon: 0.7700662 step 1000 learning rate: 0.00025\n",
      "episode: 257 agent1 cumulative reward:  140 epsilon: 0.7691662 step 1000 learning rate: 0.00025\n",
      "episode: 258 agent1 cumulative reward:  67 epsilon: 0.7682662 step 1000 learning rate: 0.00025\n",
      "episode: 259 agent1 cumulative reward:  79 epsilon: 0.7673662 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 260 agent1 cumulative reward:  96 epsilon: 0.7664662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 261 agent1 cumulative reward:  107 epsilon: 0.7655662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 262 agent1 cumulative reward:  90 epsilon: 0.7646662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 263 agent1 cumulative reward:  120 epsilon: 0.7637662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 264 agent1 cumulative reward:  95 epsilon: 0.7628662 step 1000 learning rate: 0.00025\n",
      "episode: 265 agent1 cumulative reward:  110 epsilon: 0.7619662 step 1000 learning rate: 0.00025\n",
      "episode: 266 agent1 cumulative reward:  98 epsilon: 0.7610662 step 1000 learning rate: 0.00025\n",
      "episode: 267 agent1 cumulative reward:  99 epsilon: 0.7601662 step 1000 learning rate: 0.00025\n",
      "episode: 268 agent1 cumulative reward:  94 epsilon: 0.7592662 step 1000 learning rate: 0.00025\n",
      "episode: 269 agent1 cumulative reward:  91 epsilon: 0.7583662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 270 agent1 cumulative reward:  70 epsilon: 0.7574662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 271 agent1 cumulative reward:  116 epsilon: 0.7565662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 272 agent1 cumulative reward:  114 epsilon: 0.7556662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 273 agent1 cumulative reward:  72 epsilon: 0.7547662 step 1000 learning rate: 0.00025\n",
      "episode: 274 agent1 cumulative reward:  86 epsilon: 0.7538662 step 1000 learning rate: 0.00025\n",
      "episode: 275 agent1 cumulative reward:  124 epsilon: 0.7529662 step 1000 learning rate: 0.00025\n",
      "episode: 276 agent1 cumulative reward:  111 epsilon: 0.7520662 step 1000 learning rate: 0.00025\n",
      "episode: 277 agent1 cumulative reward:  114 epsilon: 0.7511662 step 1000 learning rate: 0.00025\n",
      "episode: 278 agent1 cumulative reward:  106 epsilon: 0.7502662 step 1000 learning rate: 0.00025\n",
      "episode: 279 agent1 cumulative reward:  89 epsilon: 0.7493662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 280 agent1 cumulative reward:  109 epsilon: 0.7484662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 281 agent1 cumulative reward:  87 epsilon: 0.7475662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 282 agent1 cumulative reward:  106 epsilon: 0.7466662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 283 agent1 cumulative reward:  103 epsilon: 0.7457662 step 1000 learning rate: 0.00025\n",
      "episode: 284 agent1 cumulative reward:  79 epsilon: 0.7448662 step 1000 learning rate: 0.00025\n",
      "episode: 285 agent1 cumulative reward:  97 epsilon: 0.7439662 step 1000 learning rate: 0.00025\n",
      "episode: 286 agent1 cumulative reward:  124 epsilon: 0.7430662 step 1000 learning rate: 0.00025\n",
      "episode: 287 agent1 cumulative reward:  119 epsilon: 0.7421662 step 1000 learning rate: 0.00025\n",
      "episode: 288 agent1 cumulative reward:  126 epsilon: 0.7412662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 289 agent1 cumulative reward:  105 epsilon: 0.7403662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 290 agent1 cumulative reward:  92 epsilon: 0.7394662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 291 agent1 cumulative reward:  96 epsilon: 0.7385662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 292 agent1 cumulative reward:  92 epsilon: 0.7376662 step 1000 learning rate: 0.00025\n",
      "episode: 293 agent1 cumulative reward:  92 epsilon: 0.7367662 step 1000 learning rate: 0.00025\n",
      "episode: 294 agent1 cumulative reward:  86 epsilon: 0.7358662 step 1000 learning rate: 0.00025\n",
      "episode: 295 agent1 cumulative reward:  85 epsilon: 0.7349662 step 1000 learning rate: 0.00025\n",
      "episode: 296 agent1 cumulative reward:  127 epsilon: 0.7340662 step 1000 learning rate: 0.00025\n",
      "episode: 297 agent1 cumulative reward:  95 epsilon: 0.7331662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 298 agent1 cumulative reward:  78 epsilon: 0.7322662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 299 agent1 cumulative reward:  88 epsilon: 0.7313662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 300 agent1 cumulative reward:  95 epsilon: 0.7304662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 301 agent1 cumulative reward:  121 epsilon: 0.7295662 step 1000 learning rate: 0.00025\n",
      "episode: 302 agent1 cumulative reward:  82 epsilon: 0.7286662 step 1000 learning rate: 0.00025\n",
      "episode: 303 agent1 cumulative reward:  130 epsilon: 0.7277662 step 1000 learning rate: 0.00025\n",
      "episode: 304 agent1 cumulative reward:  73 epsilon: 0.7268662 step 1000 learning rate: 0.00025\n",
      "episode: 305 agent1 cumulative reward:  120 epsilon: 0.7259662 step 1000 learning rate: 0.00025\n",
      "episode: 306 agent1 cumulative reward:  122 epsilon: 0.7250662 step 1000 learning rate: 0.00025\n",
      "episode: 307 agent1 cumulative reward:  110 epsilon: 0.7241662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 308 agent1 cumulative reward:  121 epsilon: 0.7232662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 309 agent1 cumulative reward:  98 epsilon: 0.7223662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 310 agent1 cumulative reward:  67 epsilon: 0.7214662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 311 agent1 cumulative reward:  85 epsilon: 0.7205662 step 1000 learning rate: 0.00025\n",
      "episode: 312 agent1 cumulative reward:  124 epsilon: 0.7196662 step 1000 learning rate: 0.00025\n",
      "episode: 313 agent1 cumulative reward:  130 epsilon: 0.7187662 step 1000 learning rate: 0.00025\n",
      "episode: 314 agent1 cumulative reward:  122 epsilon: 0.7178662 step 1000 learning rate: 0.00025\n",
      "episode: 315 agent1 cumulative reward:  101 epsilon: 0.7169662 step 1000 learning rate: 0.00025\n",
      "episode: 316 agent1 cumulative reward:  106 epsilon: 0.7160662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 317 agent1 cumulative reward:  119 epsilon: 0.7151662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 318 agent1 cumulative reward:  96 epsilon: 0.7142662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 319 agent1 cumulative reward:  90 epsilon: 0.7133662000000001 step 1000 learning rate: 0.00025\n",
      "episode: 320 agent1 cumulative reward:  130 epsilon: 0.7124662 step 1000 learning rate: 0.00025\n",
      "episode: 321 agent1 cumulative reward:  106 epsilon: 0.7115662 step 1000 learning rate: 0.00025\n",
      "episode: 322 agent1 cumulative reward:  112 epsilon: 0.7106662 step 1000 learning rate: 0.00025\n",
      "episode: 323 agent1 cumulative reward:  119 epsilon: 0.7097662 step 1000 learning rate: 0.00025\n",
      "episode: 324 agent1 cumulative reward:  100 epsilon: 0.708886 step 978 learning rate: 0.00025\n",
      "episode: 325 agent1 cumulative reward:  113 epsilon: 0.707986 step 1000 learning rate: 0.00025\n",
      "episode: 326 agent1 cumulative reward:  90 epsilon: 0.707086 step 1000 learning rate: 0.00025\n",
      "episode: 327 agent1 cumulative reward:  92 epsilon: 0.706186 step 1000 learning rate: 0.00025\n",
      "episode: 328 agent1 cumulative reward:  132 epsilon: 0.705286 step 1000 learning rate: 0.00025\n",
      "episode: 329 agent1 cumulative reward:  121 epsilon: 0.704386 step 1000 learning rate: 0.00025\n",
      "episode: 330 agent1 cumulative reward:  100 epsilon: 0.703486 step 1000 learning rate: 0.00025\n",
      "episode: 331 agent1 cumulative reward:  133 epsilon: 0.7025859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 332 agent1 cumulative reward:  100 epsilon: 0.701686 step 1000 learning rate: 0.00025\n",
      "episode: 333 agent1 cumulative reward:  120 epsilon: 0.700786 step 1000 learning rate: 0.00025\n",
      "episode: 334 agent1 cumulative reward:  113 epsilon: 0.699886 step 1000 learning rate: 0.00025\n",
      "episode: 335 agent1 cumulative reward:  99 epsilon: 0.698986 step 1000 learning rate: 0.00025\n",
      "episode: 336 agent1 cumulative reward:  113 epsilon: 0.698086 step 1000 learning rate: 0.00025\n",
      "episode: 337 agent1 cumulative reward:  137 epsilon: 0.697186 step 1000 learning rate: 0.00025\n",
      "episode: 338 agent1 cumulative reward:  103 epsilon: 0.696286 step 1000 learning rate: 0.00025\n",
      "episode: 339 agent1 cumulative reward:  132 epsilon: 0.695386 step 1000 learning rate: 0.00025\n",
      "episode: 340 agent1 cumulative reward:  112 epsilon: 0.6944859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 341 agent1 cumulative reward:  127 epsilon: 0.6935859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 342 agent1 cumulative reward:  92 epsilon: 0.692686 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 343 agent1 cumulative reward:  70 epsilon: 0.691786 step 1000 learning rate: 0.00025\n",
      "episode: 344 agent1 cumulative reward:  83 epsilon: 0.690886 step 1000 learning rate: 0.00025\n",
      "episode: 345 agent1 cumulative reward:  80 epsilon: 0.689986 step 1000 learning rate: 0.00025\n",
      "episode: 346 agent1 cumulative reward:  123 epsilon: 0.689086 step 1000 learning rate: 0.00025\n",
      "episode: 347 agent1 cumulative reward:  120 epsilon: 0.688186 step 1000 learning rate: 0.00025\n",
      "episode: 348 agent1 cumulative reward:  109 epsilon: 0.687286 step 1000 learning rate: 0.00025\n",
      "episode: 349 agent1 cumulative reward:  126 epsilon: 0.6863859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 350 agent1 cumulative reward:  110 epsilon: 0.6854859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 351 agent1 cumulative reward:  121 epsilon: 0.684586 step 1000 learning rate: 0.00025\n",
      "episode: 352 agent1 cumulative reward:  110 epsilon: 0.683686 step 1000 learning rate: 0.00025\n",
      "episode: 353 agent1 cumulative reward:  100 epsilon: 0.682786 step 1000 learning rate: 0.00025\n",
      "episode: 354 agent1 cumulative reward:  107 epsilon: 0.681886 step 1000 learning rate: 0.00025\n",
      "episode: 355 agent1 cumulative reward:  124 epsilon: 0.680986 step 1000 learning rate: 0.00025\n",
      "episode: 356 agent1 cumulative reward:  118 epsilon: 0.680086 step 1000 learning rate: 0.00025\n",
      "episode: 357 agent1 cumulative reward:  132 epsilon: 0.679186 step 1000 learning rate: 0.00025\n",
      "episode: 358 agent1 cumulative reward:  156 epsilon: 0.678286 step 1000 learning rate: 0.00025\n",
      "episode: 359 agent1 cumulative reward:  149 epsilon: 0.6773859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 360 agent1 cumulative reward:  99 epsilon: 0.676486 step 1000 learning rate: 0.00025\n",
      "episode: 361 agent1 cumulative reward:  93 epsilon: 0.675586 step 1000 learning rate: 0.00025\n",
      "episode: 362 agent1 cumulative reward:  102 epsilon: 0.674686 step 1000 learning rate: 0.00025\n",
      "episode: 363 agent1 cumulative reward:  86 epsilon: 0.673786 step 1000 learning rate: 0.00025\n",
      "episode: 364 agent1 cumulative reward:  100 epsilon: 0.672886 step 1000 learning rate: 0.00025\n",
      "episode: 365 agent1 cumulative reward:  100 epsilon: 0.671986 step 1000 learning rate: 0.00025\n",
      "episode: 366 agent1 cumulative reward:  150 epsilon: 0.671086 step 1000 learning rate: 0.00025\n",
      "episode: 367 agent1 cumulative reward:  99 epsilon: 0.670186 step 1000 learning rate: 0.00025\n",
      "episode: 368 agent1 cumulative reward:  109 epsilon: 0.6692859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 369 agent1 cumulative reward:  133 epsilon: 0.6683859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 370 agent1 cumulative reward:  82 epsilon: 0.667486 step 1000 learning rate: 0.00025\n",
      "episode: 371 agent1 cumulative reward:  120 epsilon: 0.666586 step 1000 learning rate: 0.00025\n",
      "episode: 372 agent1 cumulative reward:  96 epsilon: 0.665686 step 1000 learning rate: 0.00025\n",
      "episode: 373 agent1 cumulative reward:  160 epsilon: 0.664786 step 1000 learning rate: 0.00025\n",
      "episode: 374 agent1 cumulative reward:  145 epsilon: 0.663886 step 1000 learning rate: 0.00025\n",
      "episode: 375 agent1 cumulative reward:  107 epsilon: 0.662986 step 1000 learning rate: 0.00025\n",
      "episode: 376 agent1 cumulative reward:  152 epsilon: 0.662086 step 1000 learning rate: 0.00025\n",
      "episode: 377 agent1 cumulative reward:  133 epsilon: 0.6611859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 378 agent1 cumulative reward:  138 epsilon: 0.6602859999999999 step 1000 learning rate: 0.00025\n",
      "episode: 379 agent1 cumulative reward:  94 epsilon: 0.659386 step 1000 learning rate: 0.00025\n",
      "episode: 380 agent1 cumulative reward:  111 epsilon: 0.6585166 step 966 learning rate: 0.00025\n",
      "episode: 381 agent1 cumulative reward:  155 epsilon: 0.6576166 step 1000 learning rate: 0.00025\n",
      "episode: 382 agent1 cumulative reward:  104 epsilon: 0.6567166 step 1000 learning rate: 0.00025\n",
      "episode: 383 agent1 cumulative reward:  136 epsilon: 0.6558166 step 1000 learning rate: 0.00025\n",
      "episode: 384 agent1 cumulative reward:  131 epsilon: 0.6549166 step 1000 learning rate: 0.00025\n",
      "episode: 385 agent1 cumulative reward:  74 epsilon: 0.6540166 step 1000 learning rate: 0.00025\n",
      "episode: 386 agent1 cumulative reward:  131 epsilon: 0.6531165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 387 agent1 cumulative reward:  110 epsilon: 0.6522165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 388 agent1 cumulative reward:  138 epsilon: 0.6513165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 389 agent1 cumulative reward:  123 epsilon: 0.6504165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 390 agent1 cumulative reward:  79 epsilon: 0.6495166 step 1000 learning rate: 0.00025\n",
      "episode: 391 agent1 cumulative reward:  81 epsilon: 0.6486166 step 1000 learning rate: 0.00025\n",
      "episode: 392 agent1 cumulative reward:  107 epsilon: 0.6477166 step 1000 learning rate: 0.00025\n",
      "episode: 393 agent1 cumulative reward:  93 epsilon: 0.6468166 step 1000 learning rate: 0.00025\n",
      "episode: 394 agent1 cumulative reward:  134 epsilon: 0.6459166 step 1000 learning rate: 0.00025\n",
      "episode: 395 agent1 cumulative reward:  93 epsilon: 0.6450165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 396 agent1 cumulative reward:  80 epsilon: 0.6441165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 397 agent1 cumulative reward:  119 epsilon: 0.6432165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 398 agent1 cumulative reward:  110 epsilon: 0.6423165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 399 agent1 cumulative reward:  149 epsilon: 0.6414166 step 1000 learning rate: 0.00025\n",
      "episode: 400 agent1 cumulative reward:  122 epsilon: 0.6405166 step 1000 learning rate: 0.00025\n",
      "episode: 401 agent1 cumulative reward:  129 epsilon: 0.6396166 step 1000 learning rate: 0.00025\n",
      "episode: 402 agent1 cumulative reward:  116 epsilon: 0.6387166 step 1000 learning rate: 0.00025\n",
      "episode: 403 agent1 cumulative reward:  126 epsilon: 0.6378166 step 1000 learning rate: 0.00025\n",
      "episode: 404 agent1 cumulative reward:  146 epsilon: 0.6369165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 405 agent1 cumulative reward:  108 epsilon: 0.6360165999999999 step 1000 learning rate: 0.00025\n",
      "episode: 406 agent1 cumulative reward:  91 epsilon: 0.6352417 step 861 learning rate: 0.00025\n",
      "episode: 407 agent1 cumulative reward:  116 epsilon: 0.6343417 step 1000 learning rate: 0.00025\n",
      "episode: 408 agent1 cumulative reward:  127 epsilon: 0.6334417 step 1000 learning rate: 0.00025\n",
      "episode: 409 agent1 cumulative reward:  126 epsilon: 0.6325417000000001 step 1000 learning rate: 0.00025\n",
      "episode: 410 agent1 cumulative reward:  105 epsilon: 0.6317794 step 847 learning rate: 0.00025\n",
      "episode: 411 agent1 cumulative reward:  119 epsilon: 0.6308794 step 1000 learning rate: 0.00025\n",
      "episode: 412 agent1 cumulative reward:  112 epsilon: 0.6301675 step 791 learning rate: 0.00025\n",
      "episode: 413 agent1 cumulative reward:  120 epsilon: 0.6292675 step 1000 learning rate: 0.00025\n",
      "episode: 414 agent1 cumulative reward:  110 epsilon: 0.6283675 step 1000 learning rate: 0.00025\n",
      "episode: 415 agent1 cumulative reward:  127 epsilon: 0.6274675 step 1000 learning rate: 0.00025\n",
      "episode: 416 agent1 cumulative reward:  99 epsilon: 0.6265674999999999 step 1000 learning rate: 0.00025\n",
      "episode: 417 agent1 cumulative reward:  91 epsilon: 0.6256674999999999 step 1000 learning rate: 0.00025\n",
      "episode: 418 agent1 cumulative reward:  89 epsilon: 0.6251185 step 610 learning rate: 0.00025\n",
      "episode: 419 agent1 cumulative reward:  96 epsilon: 0.6244543 step 738 learning rate: 0.00025\n",
      "episode: 420 agent1 cumulative reward:  140 epsilon: 0.6235543 step 1000 learning rate: 0.00025\n",
      "episode: 421 agent1 cumulative reward:  76 epsilon: 0.6226543 step 1000 learning rate: 0.00025\n",
      "episode: 422 agent1 cumulative reward:  92 epsilon: 0.6217543 step 1000 learning rate: 0.00025\n",
      "episode: 423 agent1 cumulative reward:  145 epsilon: 0.6208543 step 1000 learning rate: 0.00025\n",
      "episode: 424 agent1 cumulative reward:  99 epsilon: 0.6199543 step 1000 learning rate: 0.00025\n",
      "episode: 425 agent1 cumulative reward:  99 epsilon: 0.6190543 step 1000 learning rate: 0.00025\n",
      "episode: 426 agent1 cumulative reward:  124 epsilon: 0.6181542999999999 step 1000 learning rate: 0.00025\n",
      "episode: 427 agent1 cumulative reward:  91 epsilon: 0.6172542999999999 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 428 agent1 cumulative reward:  93 epsilon: 0.6163543 step 1000 learning rate: 0.00025\n",
      "episode: 429 agent1 cumulative reward:  100 epsilon: 0.6154543 step 1000 learning rate: 0.00025\n",
      "episode: 430 agent1 cumulative reward:  94 epsilon: 0.6146911 step 848 learning rate: 0.00025\n",
      "episode: 431 agent1 cumulative reward:  85 epsilon: 0.6137911 step 1000 learning rate: 0.00025\n",
      "episode: 432 agent1 cumulative reward:  113 epsilon: 0.6128911 step 1000 learning rate: 0.00025\n",
      "episode: 433 agent1 cumulative reward:  117 epsilon: 0.6119911 step 1000 learning rate: 0.00025\n",
      "episode: 434 agent1 cumulative reward:  109 epsilon: 0.6110911 step 1000 learning rate: 0.00025\n",
      "episode: 435 agent1 cumulative reward:  138 epsilon: 0.6101911 step 1000 learning rate: 0.00025\n",
      "episode: 436 agent1 cumulative reward:  108 epsilon: 0.6092911 step 1000 learning rate: 0.00025\n",
      "episode: 437 agent1 cumulative reward:  84 epsilon: 0.6083911 step 1000 learning rate: 0.00025\n",
      "episode: 438 agent1 cumulative reward:  161 epsilon: 0.6074911000000001 step 1000 learning rate: 0.00025\n",
      "episode: 439 agent1 cumulative reward:  127 epsilon: 0.6066082 step 981 learning rate: 0.00025\n",
      "episode: 440 agent1 cumulative reward:  134 epsilon: 0.6057082 step 1000 learning rate: 0.00025\n",
      "episode: 441 agent1 cumulative reward:  134 epsilon: 0.6048082 step 1000 learning rate: 0.00025\n",
      "episode: 442 agent1 cumulative reward:  117 epsilon: 0.6039082 step 1000 learning rate: 0.00025\n",
      "episode: 443 agent1 cumulative reward:  119 epsilon: 0.6030082 step 1000 learning rate: 0.00025\n",
      "episode: 444 agent1 cumulative reward:  111 epsilon: 0.6021082 step 1000 learning rate: 0.00025\n",
      "episode: 445 agent1 cumulative reward:  128 epsilon: 0.6012082 step 1000 learning rate: 0.00025\n",
      "episode: 446 agent1 cumulative reward:  97 epsilon: 0.6003082 step 1000 learning rate: 0.00025\n",
      "episode: 447 agent1 cumulative reward:  65 epsilon: 0.5994082000000001 step 1000 learning rate: 0.00025\n",
      "episode: 448 agent1 cumulative reward:  130 epsilon: 0.5985082 step 1000 learning rate: 0.00025\n",
      "episode: 449 agent1 cumulative reward:  124 epsilon: 0.5976082 step 1000 learning rate: 0.00025\n",
      "episode: 450 agent1 cumulative reward:  105 epsilon: 0.5967082 step 1000 learning rate: 0.00025\n",
      "episode: 451 agent1 cumulative reward:  122 epsilon: 0.5958082 step 1000 learning rate: 0.00025\n",
      "episode: 452 agent1 cumulative reward:  97 epsilon: 0.5949082 step 1000 learning rate: 0.00025\n",
      "episode: 453 agent1 cumulative reward:  75 epsilon: 0.5940082 step 1000 learning rate: 0.00025\n",
      "episode: 454 agent1 cumulative reward:  119 epsilon: 0.5931082 step 1000 learning rate: 0.00025\n",
      "episode: 455 agent1 cumulative reward:  117 epsilon: 0.5922082 step 1000 learning rate: 0.00025\n",
      "episode: 456 agent1 cumulative reward:  115 epsilon: 0.5913082000000001 step 1000 learning rate: 0.00025\n",
      "episode: 457 agent1 cumulative reward:  90 epsilon: 0.5904082 step 1000 learning rate: 0.00025\n",
      "episode: 458 agent1 cumulative reward:  92 epsilon: 0.5895082 step 1000 learning rate: 0.00025\n",
      "episode: 459 agent1 cumulative reward:  107 epsilon: 0.5886082 step 1000 learning rate: 0.00025\n",
      "episode: 460 agent1 cumulative reward:  151 epsilon: 0.5877082 step 1000 learning rate: 0.00025\n",
      "episode: 461 agent1 cumulative reward:  66 epsilon: 0.5868082 step 1000 learning rate: 0.00025\n",
      "episode: 462 agent1 cumulative reward:  87 epsilon: 0.5859082 step 1000 learning rate: 0.00025\n",
      "episode: 463 agent1 cumulative reward:  154 epsilon: 0.5850082 step 1000 learning rate: 0.00025\n",
      "episode: 464 agent1 cumulative reward:  96 epsilon: 0.5841082 step 1000 learning rate: 0.00025\n",
      "episode: 465 agent1 cumulative reward:  127 epsilon: 0.5832082000000001 step 1000 learning rate: 0.00025\n",
      "episode: 466 agent1 cumulative reward:  99 epsilon: 0.5823721000000001 step 929 learning rate: 0.00025\n",
      "episode: 467 agent1 cumulative reward:  106 epsilon: 0.5814721 step 1000 learning rate: 0.00025\n",
      "episode: 468 agent1 cumulative reward:  132 epsilon: 0.5805721 step 1000 learning rate: 0.00025\n",
      "episode: 469 agent1 cumulative reward:  108 epsilon: 0.5796721 step 1000 learning rate: 0.00025\n",
      "episode: 470 agent1 cumulative reward:  122 epsilon: 0.5787721 step 1000 learning rate: 0.00025\n",
      "episode: 471 agent1 cumulative reward:  161 epsilon: 0.5778721 step 1000 learning rate: 0.00025\n",
      "episode: 472 agent1 cumulative reward:  77 epsilon: 0.5769721 step 1000 learning rate: 0.00025\n",
      "episode: 473 agent1 cumulative reward:  130 epsilon: 0.5760721000000001 step 1000 learning rate: 0.00025\n",
      "episode: 474 agent1 cumulative reward:  98 epsilon: 0.5751721000000001 step 1000 learning rate: 0.00025\n",
      "episode: 475 agent1 cumulative reward:  126 epsilon: 0.5742721000000001 step 1000 learning rate: 0.00025\n",
      "episode: 476 agent1 cumulative reward:  93 epsilon: 0.5733721 step 1000 learning rate: 0.00025\n",
      "episode: 477 agent1 cumulative reward:  121 epsilon: 0.5725171 step 950 learning rate: 0.00025\n",
      "episode: 478 agent1 cumulative reward:  125 epsilon: 0.5716171 step 1000 learning rate: 0.00025\n",
      "episode: 479 agent1 cumulative reward:  94 epsilon: 0.5708359000000001 step 868 learning rate: 0.00025\n",
      "episode: 480 agent1 cumulative reward:  112 epsilon: 0.5699359 step 1000 learning rate: 0.00025\n",
      "episode: 481 agent1 cumulative reward:  128 epsilon: 0.5690359 step 1000 learning rate: 0.00025\n",
      "episode: 482 agent1 cumulative reward:  102 epsilon: 0.5681359 step 1000 learning rate: 0.00025\n",
      "episode: 483 agent1 cumulative reward:  110 epsilon: 0.5672359 step 1000 learning rate: 0.00025\n",
      "episode: 484 agent1 cumulative reward:  76 epsilon: 0.5663359 step 1000 learning rate: 0.00025\n",
      "episode: 485 agent1 cumulative reward:  113 epsilon: 0.5654359 step 1000 learning rate: 0.00025\n",
      "episode: 486 agent1 cumulative reward:  143 epsilon: 0.5645485 step 986 learning rate: 0.00025\n",
      "episode: 487 agent1 cumulative reward:  93 epsilon: 0.5636872 step 957 learning rate: 0.00025\n",
      "episode: 488 agent1 cumulative reward:  166 epsilon: 0.5627872 step 1000 learning rate: 0.00025\n",
      "episode: 489 agent1 cumulative reward:  143 epsilon: 0.5619043 step 981 learning rate: 0.00025\n",
      "episode: 490 agent1 cumulative reward:  154 epsilon: 0.5610043 step 1000 learning rate: 0.00025\n",
      "episode: 491 agent1 cumulative reward:  130 epsilon: 0.5601043 step 1000 learning rate: 0.00025\n",
      "episode: 492 agent1 cumulative reward:  173 epsilon: 0.5592043 step 1000 learning rate: 0.00025\n",
      "episode: 493 agent1 cumulative reward:  157 epsilon: 0.5583043 step 1000 learning rate: 0.00025\n",
      "episode: 494 agent1 cumulative reward:  119 epsilon: 0.5574043 step 1000 learning rate: 0.00025\n",
      "episode: 495 agent1 cumulative reward:  137 epsilon: 0.5565043 step 1000 learning rate: 0.00025\n",
      "episode: 496 agent1 cumulative reward:  133 epsilon: 0.5556042999999999 step 1000 learning rate: 0.00025\n",
      "episode: 497 agent1 cumulative reward:  132 epsilon: 0.5547043 step 1000 learning rate: 0.00025\n",
      "episode: 498 agent1 cumulative reward:  146 epsilon: 0.5538043 step 1000 learning rate: 0.00025\n",
      "episode: 499 agent1 cumulative reward:  95 epsilon: 0.5529043 step 1000 learning rate: 0.00025\n",
      "episode: 500 agent1 cumulative reward:  99 epsilon: 0.5520043 step 1000 learning rate: 0.00025\n",
      "episode: 501 agent1 cumulative reward:  124 epsilon: 0.5511043 step 1000 learning rate: 0.00025\n",
      "episode: 502 agent1 cumulative reward:  134 epsilon: 0.5502043 step 1000 learning rate: 0.00025\n",
      "episode: 503 agent1 cumulative reward:  98 epsilon: 0.5493043 step 1000 learning rate: 0.00025\n",
      "episode: 504 agent1 cumulative reward:  97 epsilon: 0.5484448 step 955 learning rate: 0.00025\n",
      "episode: 505 agent1 cumulative reward:  114 epsilon: 0.5477095 step 817 learning rate: 0.00025\n",
      "episode: 506 agent1 cumulative reward:  131 epsilon: 0.5468284 step 979 learning rate: 0.00025\n",
      "episode: 507 agent1 cumulative reward:  102 epsilon: 0.5459284 step 1000 learning rate: 0.00025\n",
      "episode: 508 agent1 cumulative reward:  121 epsilon: 0.5450284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 509 agent1 cumulative reward:  132 epsilon: 0.5441284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 510 agent1 cumulative reward:  109 epsilon: 0.5432284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 511 agent1 cumulative reward:  162 epsilon: 0.5423284 step 1000 learning rate: 0.00025\n",
      "episode: 512 agent1 cumulative reward:  103 epsilon: 0.5414284 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 513 agent1 cumulative reward:  111 epsilon: 0.5405284 step 1000 learning rate: 0.00025\n",
      "episode: 514 agent1 cumulative reward:  123 epsilon: 0.5396284 step 1000 learning rate: 0.00025\n",
      "episode: 515 agent1 cumulative reward:  112 epsilon: 0.5387284 step 1000 learning rate: 0.00025\n",
      "episode: 516 agent1 cumulative reward:  111 epsilon: 0.5378284 step 1000 learning rate: 0.00025\n",
      "episode: 517 agent1 cumulative reward:  103 epsilon: 0.5369284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 518 agent1 cumulative reward:  131 epsilon: 0.5360284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 519 agent1 cumulative reward:  91 epsilon: 0.5351284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 520 agent1 cumulative reward:  115 epsilon: 0.5342284 step 1000 learning rate: 0.00025\n",
      "episode: 521 agent1 cumulative reward:  103 epsilon: 0.5333284 step 1000 learning rate: 0.00025\n",
      "episode: 522 agent1 cumulative reward:  109 epsilon: 0.5324284 step 1000 learning rate: 0.00025\n",
      "episode: 523 agent1 cumulative reward:  94 epsilon: 0.5315284 step 1000 learning rate: 0.00025\n",
      "episode: 524 agent1 cumulative reward:  103 epsilon: 0.5306284 step 1000 learning rate: 0.00025\n",
      "episode: 525 agent1 cumulative reward:  133 epsilon: 0.5297284 step 1000 learning rate: 0.00025\n",
      "episode: 526 agent1 cumulative reward:  149 epsilon: 0.5288284 step 1000 learning rate: 0.00025\n",
      "episode: 527 agent1 cumulative reward:  161 epsilon: 0.5279284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 528 agent1 cumulative reward:  137 epsilon: 0.5270284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 529 agent1 cumulative reward:  117 epsilon: 0.5261284 step 1000 learning rate: 0.00025\n",
      "episode: 530 agent1 cumulative reward:  158 epsilon: 0.5252284 step 1000 learning rate: 0.00025\n",
      "episode: 531 agent1 cumulative reward:  142 epsilon: 0.5243284 step 1000 learning rate: 0.00025\n",
      "episode: 532 agent1 cumulative reward:  122 epsilon: 0.5234284 step 1000 learning rate: 0.00025\n",
      "episode: 533 agent1 cumulative reward:  148 epsilon: 0.5225284 step 1000 learning rate: 0.00025\n",
      "episode: 534 agent1 cumulative reward:  149 epsilon: 0.5216284 step 1000 learning rate: 0.00025\n",
      "episode: 535 agent1 cumulative reward:  80 epsilon: 0.5207284 step 1000 learning rate: 0.00025\n",
      "episode: 536 agent1 cumulative reward:  78 epsilon: 0.5198284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 537 agent1 cumulative reward:  110 epsilon: 0.5189284000000001 step 1000 learning rate: 0.00025\n",
      "episode: 538 agent1 cumulative reward:  90 epsilon: 0.5180284 step 1000 learning rate: 0.00025\n",
      "episode: 539 agent1 cumulative reward:  145 epsilon: 0.5171284 step 1000 learning rate: 0.00025\n",
      "episode: 540 agent1 cumulative reward:  105 epsilon: 0.5163994000000001 step 810 learning rate: 0.00025\n",
      "episode: 541 agent1 cumulative reward:  121 epsilon: 0.5155048 step 994 learning rate: 0.00025\n",
      "episode: 542 agent1 cumulative reward:  136 epsilon: 0.5146048 step 1000 learning rate: 0.00025\n",
      "episode: 543 agent1 cumulative reward:  124 epsilon: 0.5137048 step 1000 learning rate: 0.00025\n",
      "episode: 544 agent1 cumulative reward:  136 epsilon: 0.5128048 step 1000 learning rate: 0.00025\n",
      "episode: 545 agent1 cumulative reward:  83 epsilon: 0.5119048 step 1000 learning rate: 0.00025\n",
      "episode: 546 agent1 cumulative reward:  184 epsilon: 0.5110048 step 1000 learning rate: 0.00025\n",
      "episode: 547 agent1 cumulative reward:  152 epsilon: 0.5101048 step 1000 learning rate: 0.00025\n",
      "episode: 548 agent1 cumulative reward:  149 epsilon: 0.5092048 step 1000 learning rate: 0.00025\n",
      "episode: 549 agent1 cumulative reward:  181 epsilon: 0.5083048 step 1000 learning rate: 0.00025\n",
      "episode: 550 agent1 cumulative reward:  134 epsilon: 0.5074048 step 1000 learning rate: 0.00025\n",
      "episode: 551 agent1 cumulative reward:  173 epsilon: 0.5065048 step 1000 learning rate: 0.00025\n",
      "episode: 552 agent1 cumulative reward:  101 epsilon: 0.5056048 step 1000 learning rate: 0.00025\n",
      "episode: 553 agent1 cumulative reward:  187 epsilon: 0.5047048 step 1000 learning rate: 0.00025\n",
      "episode: 554 agent1 cumulative reward:  72 epsilon: 0.5038047999999999 step 1000 learning rate: 0.00025\n",
      "episode: 555 agent1 cumulative reward:  134 epsilon: 0.5029048 step 1000 learning rate: 0.00025\n",
      "episode: 556 agent1 cumulative reward:  131 epsilon: 0.5020048 step 1000 learning rate: 0.00025\n",
      "episode: 557 agent1 cumulative reward:  107 epsilon: 0.5011048 step 1000 learning rate: 0.00025\n",
      "episode: 558 agent1 cumulative reward:  156 epsilon: 0.5002318 step 970 learning rate: 0.00025\n",
      "episode: 559 agent1 cumulative reward:  185 epsilon: 0.4993318 step 1000 learning rate: 0.00025\n",
      "episode: 560 agent1 cumulative reward:  162 epsilon: 0.49851460000000003 step 908 learning rate: 0.00025\n",
      "episode: 561 agent1 cumulative reward:  156 epsilon: 0.4976146 step 1000 learning rate: 0.00025\n",
      "episode: 562 agent1 cumulative reward:  90 epsilon: 0.4967146 step 1000 learning rate: 0.00025\n",
      "episode: 563 agent1 cumulative reward:  115 epsilon: 0.4958146 step 1000 learning rate: 0.00025\n",
      "episode: 564 agent1 cumulative reward:  187 epsilon: 0.4949146000000001 step 1000 learning rate: 0.00025\n",
      "episode: 565 agent1 cumulative reward:  107 epsilon: 0.49428190000000005 step 703 learning rate: 0.00025\n",
      "episode: 566 agent1 cumulative reward:  127 epsilon: 0.4934971 step 872 learning rate: 0.00025\n",
      "episode: 567 agent1 cumulative reward:  109 epsilon: 0.4925971 step 1000 learning rate: 0.00025\n",
      "episode: 568 agent1 cumulative reward:  133 epsilon: 0.4916971 step 1000 learning rate: 0.00025\n",
      "episode: 569 agent1 cumulative reward:  160 epsilon: 0.4907971 step 1000 learning rate: 0.00025\n",
      "episode: 570 agent1 cumulative reward:  112 epsilon: 0.4900186000000001 step 865 learning rate: 0.00025\n",
      "episode: 571 agent1 cumulative reward:  144 epsilon: 0.48911860000000007 step 1000 learning rate: 0.00025\n",
      "episode: 572 agent1 cumulative reward:  151 epsilon: 0.48828879999999997 step 922 learning rate: 0.00025\n",
      "episode: 573 agent1 cumulative reward:  122 epsilon: 0.48738879999999996 step 1000 learning rate: 0.00025\n",
      "episode: 574 agent1 cumulative reward:  109 epsilon: 0.48648879999999994 step 1000 learning rate: 0.00025\n",
      "episode: 575 agent1 cumulative reward:  99 epsilon: 0.48588580000000003 step 670 learning rate: 0.00025\n",
      "episode: 576 agent1 cumulative reward:  159 epsilon: 0.4849858 step 1000 learning rate: 0.00025\n",
      "episode: 577 agent1 cumulative reward:  131 epsilon: 0.4840858 step 1000 learning rate: 0.00025\n",
      "episode: 578 agent1 cumulative reward:  84 epsilon: 0.4831858 step 1000 learning rate: 0.00025\n",
      "episode: 579 agent1 cumulative reward:  80 epsilon: 0.4822858 step 1000 learning rate: 0.00025\n",
      "episode: 580 agent1 cumulative reward:  105 epsilon: 0.481618 step 742 learning rate: 0.00025\n",
      "episode: 581 agent1 cumulative reward:  122 epsilon: 0.48072879999999996 step 988 learning rate: 0.00025\n",
      "episode: 582 agent1 cumulative reward:  93 epsilon: 0.47982879999999994 step 1000 learning rate: 0.00025\n",
      "episode: 583 agent1 cumulative reward:  90 epsilon: 0.47892880000000004 step 1000 learning rate: 0.00025\n",
      "episode: 584 agent1 cumulative reward:  128 epsilon: 0.47802880000000003 step 1000 learning rate: 0.00025\n",
      "episode: 585 agent1 cumulative reward:  159 epsilon: 0.4771288 step 1000 learning rate: 0.00025\n",
      "episode: 586 agent1 cumulative reward:  117 epsilon: 0.4762288 step 1000 learning rate: 0.00025\n",
      "episode: 587 agent1 cumulative reward:  128 epsilon: 0.4753288 step 1000 learning rate: 0.00025\n",
      "episode: 588 agent1 cumulative reward:  86 epsilon: 0.4744288 step 1000 learning rate: 0.00025\n",
      "episode: 589 agent1 cumulative reward:  127 epsilon: 0.47352879999999997 step 1000 learning rate: 0.00025\n",
      "episode: 590 agent1 cumulative reward:  117 epsilon: 0.47262879999999996 step 1000 learning rate: 0.00025\n",
      "episode: 591 agent1 cumulative reward:  108 epsilon: 0.47183679999999995 step 880 learning rate: 0.00025\n",
      "episode: 592 agent1 cumulative reward:  135 epsilon: 0.47093680000000004 step 1000 learning rate: 0.00025\n",
      "episode: 593 agent1 cumulative reward:  90 epsilon: 0.47003680000000003 step 1000 learning rate: 0.00025\n",
      "episode: 594 agent1 cumulative reward:  128 epsilon: 0.4691368 step 1000 learning rate: 0.00025\n",
      "episode: 595 agent1 cumulative reward:  119 epsilon: 0.4682368 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 596 agent1 cumulative reward:  158 epsilon: 0.4673368 step 1000 learning rate: 0.00025\n",
      "episode: 597 agent1 cumulative reward:  103 epsilon: 0.4664368 step 1000 learning rate: 0.00025\n",
      "episode: 598 agent1 cumulative reward:  89 epsilon: 0.46590220000000004 step 594 learning rate: 0.00025\n",
      "episode: 599 agent1 cumulative reward:  92 epsilon: 0.4652596 step 714 learning rate: 0.00025\n",
      "episode: 600 agent1 cumulative reward:  95 epsilon: 0.4643596000000001 step 1000 learning rate: 0.00025\n",
      "episode: 601 agent1 cumulative reward:  113 epsilon: 0.4634596000000001 step 1000 learning rate: 0.00025\n",
      "episode: 602 agent1 cumulative reward:  152 epsilon: 0.46255960000000007 step 1000 learning rate: 0.00025\n",
      "episode: 603 agent1 cumulative reward:  141 epsilon: 0.46165960000000006 step 1000 learning rate: 0.00025\n",
      "episode: 604 agent1 cumulative reward:  132 epsilon: 0.46075960000000005 step 1000 learning rate: 0.00025\n",
      "episode: 605 agent1 cumulative reward:  118 epsilon: 0.45985960000000004 step 1000 learning rate: 0.00025\n",
      "episode: 606 agent1 cumulative reward:  112 epsilon: 0.45927190000000007 step 653 learning rate: 0.00025\n",
      "episode: 607 agent1 cumulative reward:  123 epsilon: 0.45837190000000005 step 1000 learning rate: 0.00025\n",
      "episode: 608 agent1 cumulative reward:  153 epsilon: 0.45747190000000004 step 1000 learning rate: 0.00025\n",
      "episode: 609 agent1 cumulative reward:  164 epsilon: 0.45657190000000003 step 1000 learning rate: 0.00025\n",
      "episode: 610 agent1 cumulative reward:  117 epsilon: 0.4556719 step 1000 learning rate: 0.00025\n",
      "episode: 611 agent1 cumulative reward:  147 epsilon: 0.4547719 step 1000 learning rate: 0.00025\n",
      "episode: 612 agent1 cumulative reward:  125 epsilon: 0.4539115 step 956 learning rate: 0.00025\n",
      "episode: 613 agent1 cumulative reward:  150 epsilon: 0.4530115 step 1000 learning rate: 0.00025\n",
      "episode: 614 agent1 cumulative reward:  124 epsilon: 0.4521115 step 1000 learning rate: 0.00025\n",
      "episode: 615 agent1 cumulative reward:  147 epsilon: 0.4512115 step 1000 learning rate: 0.00025\n",
      "episode: 616 agent1 cumulative reward:  79 epsilon: 0.4503115 step 1000 learning rate: 0.00025\n",
      "episode: 617 agent1 cumulative reward:  117 epsilon: 0.44947360000000003 step 931 learning rate: 0.00025\n",
      "episode: 618 agent1 cumulative reward:  106 epsilon: 0.4485736 step 1000 learning rate: 0.00025\n",
      "episode: 619 agent1 cumulative reward:  162 epsilon: 0.4476736 step 1000 learning rate: 0.00025\n",
      "episode: 620 agent1 cumulative reward:  158 epsilon: 0.4467736 step 1000 learning rate: 0.00025\n",
      "episode: 621 agent1 cumulative reward:  121 epsilon: 0.4458736000000001 step 1000 learning rate: 0.00025\n",
      "episode: 622 agent1 cumulative reward:  145 epsilon: 0.4449736000000001 step 1000 learning rate: 0.00025\n",
      "episode: 623 agent1 cumulative reward:  122 epsilon: 0.44407360000000007 step 1000 learning rate: 0.00025\n",
      "episode: 624 agent1 cumulative reward:  208 epsilon: 0.44317360000000006 step 1000 learning rate: 0.00025\n",
      "episode: 625 agent1 cumulative reward:  128 epsilon: 0.44227360000000004 step 1000 learning rate: 0.00025\n",
      "episode: 626 agent1 cumulative reward:  118 epsilon: 0.44137360000000003 step 1000 learning rate: 0.00025\n",
      "episode: 627 agent1 cumulative reward:  141 epsilon: 0.4404736 step 1000 learning rate: 0.00025\n",
      "episode: 628 agent1 cumulative reward:  135 epsilon: 0.4395736 step 1000 learning rate: 0.00025\n",
      "episode: 629 agent1 cumulative reward:  184 epsilon: 0.4386736 step 1000 learning rate: 0.00025\n",
      "episode: 630 agent1 cumulative reward:  132 epsilon: 0.4377736 step 1000 learning rate: 0.00025\n",
      "episode: 631 agent1 cumulative reward:  134 epsilon: 0.4368736000000001 step 1000 learning rate: 0.00025\n",
      "episode: 632 agent1 cumulative reward:  166 epsilon: 0.43597360000000007 step 1000 learning rate: 0.00025\n",
      "episode: 633 agent1 cumulative reward:  118 epsilon: 0.43507360000000006 step 1000 learning rate: 0.00025\n",
      "episode: 634 agent1 cumulative reward:  141 epsilon: 0.43423029999999996 step 937 learning rate: 0.00025\n",
      "episode: 635 agent1 cumulative reward:  141 epsilon: 0.43333029999999995 step 1000 learning rate: 0.00025\n",
      "episode: 636 agent1 cumulative reward:  110 epsilon: 0.43243030000000005 step 1000 learning rate: 0.00025\n",
      "episode: 637 agent1 cumulative reward:  138 epsilon: 0.43153030000000003 step 1000 learning rate: 0.00025\n",
      "episode: 638 agent1 cumulative reward:  100 epsilon: 0.4306303 step 1000 learning rate: 0.00025\n",
      "episode: 639 agent1 cumulative reward:  140 epsilon: 0.4297303 step 1000 learning rate: 0.00025\n",
      "episode: 640 agent1 cumulative reward:  149 epsilon: 0.4288303 step 1000 learning rate: 0.00025\n",
      "episode: 641 agent1 cumulative reward:  123 epsilon: 0.4279303 step 1000 learning rate: 0.00025\n",
      "episode: 642 agent1 cumulative reward:  152 epsilon: 0.4270303 step 1000 learning rate: 0.00025\n",
      "episode: 643 agent1 cumulative reward:  134 epsilon: 0.42613029999999996 step 1000 learning rate: 0.00025\n",
      "episode: 644 agent1 cumulative reward:  149 epsilon: 0.42523029999999995 step 1000 learning rate: 0.00025\n",
      "episode: 645 agent1 cumulative reward:  109 epsilon: 0.42433030000000005 step 1000 learning rate: 0.00025\n",
      "episode: 646 agent1 cumulative reward:  135 epsilon: 0.42343030000000004 step 1000 learning rate: 0.00025\n",
      "episode: 647 agent1 cumulative reward:  104 epsilon: 0.4225303 step 1000 learning rate: 0.00025\n",
      "episode: 648 agent1 cumulative reward:  113 epsilon: 0.4216303 step 1000 learning rate: 0.00025\n",
      "episode: 649 agent1 cumulative reward:  84 epsilon: 0.4207303 step 1000 learning rate: 0.00025\n",
      "episode: 650 agent1 cumulative reward:  133 epsilon: 0.4198303 step 1000 learning rate: 0.00025\n",
      "episode: 651 agent1 cumulative reward:  124 epsilon: 0.4189303 step 1000 learning rate: 0.00025\n",
      "episode: 652 agent1 cumulative reward:  126 epsilon: 0.4181338 step 885 learning rate: 0.00025\n",
      "episode: 653 agent1 cumulative reward:  166 epsilon: 0.4172338 step 1000 learning rate: 0.00025\n",
      "episode: 654 agent1 cumulative reward:  158 epsilon: 0.4163338 step 1000 learning rate: 0.00025\n",
      "episode: 655 agent1 cumulative reward:  179 epsilon: 0.41543379999999996 step 1000 learning rate: 0.00025\n",
      "episode: 656 agent1 cumulative reward:  102 epsilon: 0.41453379999999995 step 1000 learning rate: 0.00025\n",
      "episode: 657 agent1 cumulative reward:  117 epsilon: 0.41375530000000005 step 865 learning rate: 0.00025\n",
      "episode: 658 agent1 cumulative reward:  124 epsilon: 0.41285530000000004 step 1000 learning rate: 0.00025\n",
      "episode: 659 agent1 cumulative reward:  111 epsilon: 0.4119553 step 1000 learning rate: 0.00025\n",
      "episode: 660 agent1 cumulative reward:  122 epsilon: 0.4110553 step 1000 learning rate: 0.00025\n",
      "episode: 661 agent1 cumulative reward:  147 epsilon: 0.4101553 step 1000 learning rate: 0.00025\n",
      "episode: 662 agent1 cumulative reward:  151 epsilon: 0.4092553 step 1000 learning rate: 0.00025\n",
      "episode: 663 agent1 cumulative reward:  122 epsilon: 0.4083553 step 1000 learning rate: 0.00025\n",
      "episode: 664 agent1 cumulative reward:  124 epsilon: 0.40745529999999996 step 1000 learning rate: 0.00025\n",
      "episode: 665 agent1 cumulative reward:  161 epsilon: 0.40655529999999995 step 1000 learning rate: 0.00025\n",
      "episode: 666 agent1 cumulative reward:  105 epsilon: 0.405721 step 927 learning rate: 0.00025\n",
      "episode: 667 agent1 cumulative reward:  105 epsilon: 0.404821 step 1000 learning rate: 0.00025\n",
      "episode: 668 agent1 cumulative reward:  112 epsilon: 0.403921 step 1000 learning rate: 0.00025\n",
      "episode: 669 agent1 cumulative reward:  147 epsilon: 0.40302099999999996 step 1000 learning rate: 0.00025\n",
      "episode: 670 agent1 cumulative reward:  108 epsilon: 0.4024711000000001 step 611 learning rate: 0.00025\n",
      "episode: 671 agent1 cumulative reward:  115 epsilon: 0.40162149999999996 step 944 learning rate: 0.00025\n",
      "episode: 672 agent1 cumulative reward:  102 epsilon: 0.40095820000000004 step 737 learning rate: 0.00025\n",
      "episode: 673 agent1 cumulative reward:  92 epsilon: 0.40005820000000003 step 1000 learning rate: 0.00025\n",
      "episode: 674 agent1 cumulative reward:  128 epsilon: 0.3991582 step 1000 learning rate: 0.00025\n",
      "episode: 675 agent1 cumulative reward:  93 epsilon: 0.3982582 step 1000 learning rate: 0.00025\n",
      "episode: 676 agent1 cumulative reward:  124 epsilon: 0.3973582 step 1000 learning rate: 0.00025\n",
      "episode: 677 agent1 cumulative reward:  78 epsilon: 0.3966337 step 805 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 678 agent1 cumulative reward:  93 epsilon: 0.39573369999999997 step 1000 learning rate: 0.00025\n",
      "episode: 679 agent1 cumulative reward:  77 epsilon: 0.39483370000000007 step 1000 learning rate: 0.00025\n",
      "episode: 680 agent1 cumulative reward:  104 epsilon: 0.39395800000000003 step 973 learning rate: 0.00025\n",
      "episode: 681 agent1 cumulative reward:  120 epsilon: 0.393058 step 1000 learning rate: 0.00025\n",
      "episode: 682 agent1 cumulative reward:  131 epsilon: 0.392158 step 1000 learning rate: 0.00025\n",
      "episode: 683 agent1 cumulative reward:  101 epsilon: 0.391258 step 1000 learning rate: 0.00025\n",
      "episode: 684 agent1 cumulative reward:  114 epsilon: 0.390358 step 1000 learning rate: 0.00025\n",
      "episode: 685 agent1 cumulative reward:  119 epsilon: 0.38945799999999997 step 1000 learning rate: 0.00025\n",
      "episode: 686 agent1 cumulative reward:  120 epsilon: 0.3885967 step 957 learning rate: 0.00025\n",
      "episode: 687 agent1 cumulative reward:  82 epsilon: 0.38800270000000003 step 660 learning rate: 0.00025\n",
      "episode: 688 agent1 cumulative reward:  132 epsilon: 0.3871027 step 1000 learning rate: 0.00025\n",
      "episode: 689 agent1 cumulative reward:  150 epsilon: 0.3862027 step 1000 learning rate: 0.00025\n",
      "episode: 690 agent1 cumulative reward:  121 epsilon: 0.3853027 step 1000 learning rate: 0.00025\n",
      "episode: 691 agent1 cumulative reward:  130 epsilon: 0.3844027 step 1000 learning rate: 0.00025\n",
      "episode: 692 agent1 cumulative reward:  139 epsilon: 0.3835027 step 1000 learning rate: 0.00025\n",
      "episode: 693 agent1 cumulative reward:  144 epsilon: 0.38260269999999996 step 1000 learning rate: 0.00025\n",
      "episode: 694 agent1 cumulative reward:  123 epsilon: 0.3817207 step 980 learning rate: 0.00025\n",
      "episode: 695 agent1 cumulative reward:  134 epsilon: 0.3809251 step 884 learning rate: 0.00025\n",
      "episode: 696 agent1 cumulative reward:  92 epsilon: 0.3800251 step 1000 learning rate: 0.00025\n",
      "episode: 697 agent1 cumulative reward:  116 epsilon: 0.3791251 step 1000 learning rate: 0.00025\n",
      "episode: 698 agent1 cumulative reward:  126 epsilon: 0.3782251000000001 step 1000 learning rate: 0.00025\n",
      "episode: 699 agent1 cumulative reward:  105 epsilon: 0.3773251000000001 step 1000 learning rate: 0.00025\n",
      "episode: 700 agent1 cumulative reward:  130 epsilon: 0.37642510000000007 step 1000 learning rate: 0.00025\n",
      "episode: 701 agent1 cumulative reward:  129 epsilon: 0.37552510000000006 step 1000 learning rate: 0.00025\n",
      "episode: 702 agent1 cumulative reward:  88 epsilon: 0.37505979999999994 step 517 learning rate: 0.00025\n",
      "episode: 703 agent1 cumulative reward:  115 epsilon: 0.37415980000000004 step 1000 learning rate: 0.00025\n",
      "episode: 704 agent1 cumulative reward:  129 epsilon: 0.37342 step 822 learning rate: 0.00025\n",
      "episode: 705 agent1 cumulative reward:  143 epsilon: 0.37251999999999996 step 1000 learning rate: 0.00025\n",
      "episode: 706 agent1 cumulative reward:  116 epsilon: 0.37161999999999995 step 1000 learning rate: 0.00025\n",
      "episode: 707 agent1 cumulative reward:  144 epsilon: 0.37072000000000005 step 1000 learning rate: 0.00025\n",
      "episode: 708 agent1 cumulative reward:  118 epsilon: 0.3698659000000001 step 949 learning rate: 0.00025\n",
      "episode: 709 agent1 cumulative reward:  130 epsilon: 0.36896590000000007 step 1000 learning rate: 0.00025\n",
      "episode: 710 agent1 cumulative reward:  109 epsilon: 0.3682639 step 780 learning rate: 0.00025\n",
      "episode: 711 agent1 cumulative reward:  144 epsilon: 0.3673639000000001 step 1000 learning rate: 0.00025\n",
      "episode: 712 agent1 cumulative reward:  135 epsilon: 0.36646390000000006 step 1000 learning rate: 0.00025\n",
      "episode: 713 agent1 cumulative reward:  121 epsilon: 0.36556390000000005 step 1000 learning rate: 0.00025\n",
      "episode: 714 agent1 cumulative reward:  152 epsilon: 0.36466390000000004 step 1000 learning rate: 0.00025\n",
      "episode: 715 agent1 cumulative reward:  141 epsilon: 0.36376390000000003 step 1000 learning rate: 0.00025\n",
      "episode: 716 agent1 cumulative reward:  126 epsilon: 0.3628639 step 1000 learning rate: 0.00025\n",
      "episode: 717 agent1 cumulative reward:  141 epsilon: 0.3619639 step 1000 learning rate: 0.00025\n",
      "episode: 718 agent1 cumulative reward:  107 epsilon: 0.3610639 step 1000 learning rate: 0.00025\n",
      "episode: 719 agent1 cumulative reward:  137 epsilon: 0.3601639 step 1000 learning rate: 0.00025\n",
      "episode: 720 agent1 cumulative reward:  155 epsilon: 0.35926389999999997 step 1000 learning rate: 0.00025\n",
      "episode: 721 agent1 cumulative reward:  113 epsilon: 0.35836389999999996 step 1000 learning rate: 0.00025\n",
      "episode: 722 agent1 cumulative reward:  148 epsilon: 0.35746389999999995 step 1000 learning rate: 0.00025\n",
      "episode: 723 agent1 cumulative reward:  150 epsilon: 0.35656390000000004 step 1000 learning rate: 0.00025\n",
      "episode: 724 agent1 cumulative reward:  179 epsilon: 0.35566390000000003 step 1000 learning rate: 0.00025\n",
      "episode: 725 agent1 cumulative reward:  128 epsilon: 0.3547639 step 1000 learning rate: 0.00025\n",
      "episode: 726 agent1 cumulative reward:  165 epsilon: 0.3538639 step 1000 learning rate: 0.00025\n",
      "episode: 727 agent1 cumulative reward:  175 epsilon: 0.3529639 step 1000 learning rate: 0.00025\n",
      "episode: 728 agent1 cumulative reward:  108 epsilon: 0.3520639 step 1000 learning rate: 0.00025\n",
      "episode: 729 agent1 cumulative reward:  110 epsilon: 0.3511639 step 1000 learning rate: 0.00025\n",
      "episode: 730 agent1 cumulative reward:  107 epsilon: 0.35047989999999996 step 760 learning rate: 0.00025\n",
      "episode: 731 agent1 cumulative reward:  172 epsilon: 0.3495799 step 1000 learning rate: 0.00025\n",
      "episode: 732 agent1 cumulative reward:  124 epsilon: 0.3488221 step 842 learning rate: 0.00025\n",
      "episode: 733 agent1 cumulative reward:  129 epsilon: 0.3479221 step 1000 learning rate: 0.00025\n",
      "episode: 734 agent1 cumulative reward:  143 epsilon: 0.3470221 step 1000 learning rate: 0.00025\n",
      "episode: 735 agent1 cumulative reward:  182 epsilon: 0.3461221 step 1000 learning rate: 0.00025\n",
      "episode: 736 agent1 cumulative reward:  135 epsilon: 0.3453094 step 903 learning rate: 0.00025\n",
      "episode: 737 agent1 cumulative reward:  94 epsilon: 0.3444094 step 1000 learning rate: 0.00025\n",
      "episode: 738 agent1 cumulative reward:  55 epsilon: 0.34350939999999996 step 1000 learning rate: 0.00025\n",
      "episode: 739 agent1 cumulative reward:  98 epsilon: 0.3426094 step 1000 learning rate: 0.00025\n",
      "episode: 740 agent1 cumulative reward:  140 epsilon: 0.34180030000000006 step 899 learning rate: 0.00025\n",
      "episode: 741 agent1 cumulative reward:  91 epsilon: 0.34090030000000004 step 1000 learning rate: 0.00025\n",
      "episode: 742 agent1 cumulative reward:  102 epsilon: 0.34000030000000003 step 1000 learning rate: 0.00025\n",
      "episode: 743 agent1 cumulative reward:  180 epsilon: 0.3391003 step 1000 learning rate: 0.00025\n",
      "episode: 744 agent1 cumulative reward:  123 epsilon: 0.3382003 step 1000 learning rate: 0.00025\n",
      "episode: 745 agent1 cumulative reward:  96 epsilon: 0.3373003 step 1000 learning rate: 0.00025\n",
      "episode: 746 agent1 cumulative reward:  154 epsilon: 0.3364003 step 1000 learning rate: 0.00025\n",
      "episode: 747 agent1 cumulative reward:  83 epsilon: 0.33550030000000003 step 1000 learning rate: 0.00025\n",
      "episode: 748 agent1 cumulative reward:  176 epsilon: 0.3346003 step 1000 learning rate: 0.00025\n",
      "episode: 749 agent1 cumulative reward:  157 epsilon: 0.33370030000000006 step 1000 learning rate: 0.00025\n",
      "episode: 750 agent1 cumulative reward:  121 epsilon: 0.33280030000000005 step 1000 learning rate: 0.00025\n",
      "episode: 751 agent1 cumulative reward:  117 epsilon: 0.33190030000000004 step 1000 learning rate: 0.00025\n",
      "episode: 752 agent1 cumulative reward:  132 epsilon: 0.331048 step 947 learning rate: 0.00025\n",
      "episode: 753 agent1 cumulative reward:  86 epsilon: 0.3301786 step 966 learning rate: 0.00025\n",
      "episode: 754 agent1 cumulative reward:  111 epsilon: 0.3292786 step 1000 learning rate: 0.00025\n",
      "episode: 755 agent1 cumulative reward:  106 epsilon: 0.3283786 step 1000 learning rate: 0.00025\n",
      "episode: 756 agent1 cumulative reward:  110 epsilon: 0.3274786 step 1000 learning rate: 0.00025\n",
      "episode: 757 agent1 cumulative reward:  145 epsilon: 0.32657860000000005 step 1000 learning rate: 0.00025\n",
      "episode: 758 agent1 cumulative reward:  137 epsilon: 0.32567860000000004 step 1000 learning rate: 0.00025\n",
      "episode: 759 agent1 cumulative reward:  110 epsilon: 0.32477860000000003 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 760 agent1 cumulative reward:  107 epsilon: 0.3238786 step 1000 learning rate: 0.00025\n",
      "episode: 761 agent1 cumulative reward:  98 epsilon: 0.3230245 step 949 learning rate: 0.00025\n",
      "episode: 762 agent1 cumulative reward:  154 epsilon: 0.32212450000000004 step 1000 learning rate: 0.00025\n",
      "episode: 763 agent1 cumulative reward:  114 epsilon: 0.3212245 step 1000 learning rate: 0.00025\n",
      "episode: 764 agent1 cumulative reward:  97 epsilon: 0.3203245 step 1000 learning rate: 0.00025\n",
      "episode: 765 agent1 cumulative reward:  157 epsilon: 0.3194245 step 1000 learning rate: 0.00025\n",
      "episode: 766 agent1 cumulative reward:  147 epsilon: 0.3185245 step 1000 learning rate: 0.00025\n",
      "episode: 767 agent1 cumulative reward:  162 epsilon: 0.3176245 step 1000 learning rate: 0.00025\n",
      "episode: 768 agent1 cumulative reward:  84 epsilon: 0.31672449999999996 step 1000 learning rate: 0.00025\n",
      "episode: 769 agent1 cumulative reward:  118 epsilon: 0.3158245 step 1000 learning rate: 0.00025\n",
      "episode: 770 agent1 cumulative reward:  119 epsilon: 0.3149245 step 1000 learning rate: 0.00025\n",
      "episode: 771 agent1 cumulative reward:  177 epsilon: 0.31402450000000004 step 1000 learning rate: 0.00025\n",
      "episode: 772 agent1 cumulative reward:  121 epsilon: 0.31312450000000003 step 1000 learning rate: 0.00025\n",
      "episode: 773 agent1 cumulative reward:  120 epsilon: 0.3122245 step 1000 learning rate: 0.00025\n",
      "episode: 774 agent1 cumulative reward:  159 epsilon: 0.3113245 step 1000 learning rate: 0.00025\n",
      "episode: 775 agent1 cumulative reward:  118 epsilon: 0.3104245 step 1000 learning rate: 0.00025\n",
      "episode: 776 agent1 cumulative reward:  105 epsilon: 0.3095245 step 1000 learning rate: 0.00025\n",
      "episode: 777 agent1 cumulative reward:  146 epsilon: 0.30862449999999997 step 1000 learning rate: 0.00025\n",
      "episode: 778 agent1 cumulative reward:  128 epsilon: 0.3077245 step 1000 learning rate: 0.00025\n",
      "episode: 779 agent1 cumulative reward:  89 epsilon: 0.307027 step 775 learning rate: 0.00025\n",
      "episode: 780 agent1 cumulative reward:  106 epsilon: 0.30612700000000004 step 1000 learning rate: 0.00025\n",
      "episode: 781 agent1 cumulative reward:  74 epsilon: 0.3052531 step 971 learning rate: 0.00025\n",
      "episode: 782 agent1 cumulative reward:  104 epsilon: 0.30435310000000004 step 1000 learning rate: 0.00025\n",
      "episode: 783 agent1 cumulative reward:  163 epsilon: 0.30345310000000003 step 1000 learning rate: 0.00025\n",
      "episode: 784 agent1 cumulative reward:  67 epsilon: 0.3025531 step 1000 learning rate: 0.00025\n",
      "episode: 785 agent1 cumulative reward:  74 epsilon: 0.3016531 step 1000 learning rate: 0.00025\n",
      "episode: 786 agent1 cumulative reward:  145 epsilon: 0.3009061 step 830 learning rate: 0.00025\n",
      "episode: 787 agent1 cumulative reward:  127 epsilon: 0.3000061 step 1000 learning rate: 0.00025\n",
      "episode: 788 agent1 cumulative reward:  152 epsilon: 0.29910610000000004 step 1000 learning rate: 0.00025\n",
      "episode: 789 agent1 cumulative reward:  137 epsilon: 0.29820610000000003 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/paiss_deeprl/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.145544). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 790 agent1 cumulative reward:  119 epsilon: 0.2974744 step 813 learning rate: 0.00025\n",
      "episode: 791 agent1 cumulative reward:  159 epsilon: 0.2965744 step 1000 learning rate: 0.00025\n",
      "episode: 792 agent1 cumulative reward:  116 epsilon: 0.2956744 step 1000 learning rate: 0.00025\n",
      "episode: 793 agent1 cumulative reward:  120 epsilon: 0.2947744 step 1000 learning rate: 0.00025\n",
      "episode: 794 agent1 cumulative reward:  166 epsilon: 0.2938744 step 1000 learning rate: 0.00025\n",
      "episode: 795 agent1 cumulative reward:  100 epsilon: 0.29297439999999997 step 1000 learning rate: 0.00025\n",
      "episode: 796 agent1 cumulative reward:  147 epsilon: 0.2920744 step 1000 learning rate: 0.00025\n",
      "episode: 797 agent1 cumulative reward:  96 epsilon: 0.2911744 step 1000 learning rate: 0.00025\n",
      "episode: 798 agent1 cumulative reward:  125 epsilon: 0.2902744 step 1000 learning rate: 0.00025\n",
      "episode: 799 agent1 cumulative reward:  75 epsilon: 0.28937440000000003 step 1000 learning rate: 0.00025\n",
      "episode: 800 agent1 cumulative reward:  73 epsilon: 0.2884744 step 1000 learning rate: 0.00025\n",
      "episode: 801 agent1 cumulative reward:  59 epsilon: 0.2875744 step 1000 learning rate: 0.00025\n",
      "episode: 802 agent1 cumulative reward:  78 epsilon: 0.2866744 step 1000 learning rate: 0.00025\n",
      "episode: 803 agent1 cumulative reward:  145 epsilon: 0.2857744 step 1000 learning rate: 0.00025\n",
      "episode: 804 agent1 cumulative reward:  112 epsilon: 0.28487439999999997 step 1000 learning rate: 0.00025\n",
      "episode: 805 agent1 cumulative reward:  143 epsilon: 0.28397439999999996 step 1000 learning rate: 0.00025\n",
      "episode: 806 agent1 cumulative reward:  145 epsilon: 0.2831707 step 893 learning rate: 0.00025\n",
      "episode: 807 agent1 cumulative reward:  96 epsilon: 0.2822707 step 1000 learning rate: 0.00025\n",
      "episode: 808 agent1 cumulative reward:  93 epsilon: 0.28137070000000003 step 1000 learning rate: 0.00025\n",
      "episode: 809 agent1 cumulative reward:  90 epsilon: 0.2805976 step 859 learning rate: 0.00025\n",
      "episode: 810 agent1 cumulative reward:  105 epsilon: 0.2796976 step 1000 learning rate: 0.00025\n",
      "episode: 811 agent1 cumulative reward:  115 epsilon: 0.27897130000000003 step 807 learning rate: 0.00025\n",
      "episode: 812 agent1 cumulative reward:  94 epsilon: 0.2782036 step 853 learning rate: 0.00025\n",
      "episode: 813 agent1 cumulative reward:  137 epsilon: 0.2773036 step 1000 learning rate: 0.00025\n",
      "episode: 814 agent1 cumulative reward:  143 epsilon: 0.27640359999999997 step 1000 learning rate: 0.00025\n",
      "episode: 815 agent1 cumulative reward:  135 epsilon: 0.2755036 step 1000 learning rate: 0.00025\n",
      "episode: 816 agent1 cumulative reward:  173 epsilon: 0.2746036 step 1000 learning rate: 0.00025\n",
      "episode: 817 agent1 cumulative reward:  114 epsilon: 0.27392230000000006 step 757 learning rate: 0.00025\n",
      "episode: 818 agent1 cumulative reward:  123 epsilon: 0.27302230000000005 step 1000 learning rate: 0.00025\n",
      "episode: 819 agent1 cumulative reward:  172 epsilon: 0.27212230000000004 step 1000 learning rate: 0.00025\n",
      "episode: 820 agent1 cumulative reward:  164 epsilon: 0.2712223 step 1000 learning rate: 0.00025\n",
      "episode: 821 agent1 cumulative reward:  155 epsilon: 0.2703223 step 1000 learning rate: 0.00025\n",
      "episode: 822 agent1 cumulative reward:  111 epsilon: 0.2694223 step 1000 learning rate: 0.00025\n",
      "episode: 823 agent1 cumulative reward:  152 epsilon: 0.2685223 step 1000 learning rate: 0.00025\n",
      "episode: 824 agent1 cumulative reward:  101 epsilon: 0.26762230000000004 step 1000 learning rate: 0.00025\n",
      "episode: 825 agent1 cumulative reward:  131 epsilon: 0.2667223 step 1000 learning rate: 0.00025\n",
      "episode: 826 agent1 cumulative reward:  152 epsilon: 0.2658223 step 1000 learning rate: 0.00025\n",
      "episode: 827 agent1 cumulative reward:  113 epsilon: 0.26492230000000005 step 1000 learning rate: 0.00025\n",
      "episode: 828 agent1 cumulative reward:  148 epsilon: 0.26402230000000004 step 1000 learning rate: 0.00025\n",
      "episode: 829 agent1 cumulative reward:  147 epsilon: 0.26312230000000003 step 1000 learning rate: 0.00025\n",
      "episode: 830 agent1 cumulative reward:  119 epsilon: 0.2622223 step 1000 learning rate: 0.00025\n",
      "episode: 831 agent1 cumulative reward:  142 epsilon: 0.2613223 step 1000 learning rate: 0.00025\n",
      "episode: 832 agent1 cumulative reward:  143 epsilon: 0.2604223 step 1000 learning rate: 0.00025\n",
      "episode: 833 agent1 cumulative reward:  114 epsilon: 0.2595223 step 1000 learning rate: 0.00025\n",
      "episode: 834 agent1 cumulative reward:  121 epsilon: 0.2586223 step 1000 learning rate: 0.00025\n",
      "episode: 835 agent1 cumulative reward:  117 epsilon: 0.2577619 step 956 learning rate: 0.00025\n",
      "episode: 836 agent1 cumulative reward:  172 epsilon: 0.2568619 step 1000 learning rate: 0.00025\n",
      "episode: 837 agent1 cumulative reward:  167 epsilon: 0.25596189999999996 step 1000 learning rate: 0.00025\n",
      "episode: 838 agent1 cumulative reward:  167 epsilon: 0.2550619 step 1000 learning rate: 0.00025\n",
      "episode: 839 agent1 cumulative reward:  148 epsilon: 0.2541619 step 1000 learning rate: 0.00025\n",
      "episode: 840 agent1 cumulative reward:  113 epsilon: 0.25326190000000004 step 1000 learning rate: 0.00025\n",
      "episode: 841 agent1 cumulative reward:  119 epsilon: 0.25236190000000003 step 1000 learning rate: 0.00025\n",
      "episode: 842 agent1 cumulative reward:  164 epsilon: 0.2514619 step 1000 learning rate: 0.00025\n",
      "episode: 843 agent1 cumulative reward:  116 epsilon: 0.2505619 step 1000 learning rate: 0.00025\n",
      "episode: 844 agent1 cumulative reward:  145 epsilon: 0.2496619 step 1000 learning rate: 0.00025\n",
      "episode: 845 agent1 cumulative reward:  112 epsilon: 0.2487619 step 1000 learning rate: 0.00025\n",
      "episode: 846 agent1 cumulative reward:  162 epsilon: 0.2480041 step 842 learning rate: 0.00025\n",
      "episode: 847 agent1 cumulative reward:  132 epsilon: 0.24722650000000002 step 864 learning rate: 0.00025\n",
      "episode: 848 agent1 cumulative reward:  89 epsilon: 0.246412 step 905 learning rate: 0.00025\n",
      "episode: 849 agent1 cumulative reward:  92 epsilon: 0.245512 step 1000 learning rate: 0.00025\n",
      "episode: 850 agent1 cumulative reward:  118 epsilon: 0.2446939 step 909 learning rate: 0.00025\n",
      "episode: 851 agent1 cumulative reward:  116 epsilon: 0.2437939 step 1000 learning rate: 0.00025\n",
      "episode: 852 agent1 cumulative reward:  103 epsilon: 0.2432395 step 616 learning rate: 0.00025\n",
      "episode: 853 agent1 cumulative reward:  151 epsilon: 0.2423395 step 1000 learning rate: 0.00025\n",
      "episode: 854 agent1 cumulative reward:  158 epsilon: 0.2414395 step 1000 learning rate: 0.00025\n",
      "episode: 855 agent1 cumulative reward:  115 epsilon: 0.24053950000000002 step 1000 learning rate: 0.00025\n",
      "episode: 856 agent1 cumulative reward:  106 epsilon: 0.23987080000000002 step 743 learning rate: 0.00025\n",
      "episode: 857 agent1 cumulative reward:  136 epsilon: 0.2389708 step 1000 learning rate: 0.00025\n",
      "episode: 858 agent1 cumulative reward:  138 epsilon: 0.23807080000000003 step 1000 learning rate: 0.00025\n",
      "episode: 859 agent1 cumulative reward:  97 epsilon: 0.23733910000000003 step 813 learning rate: 0.00025\n",
      "episode: 860 agent1 cumulative reward:  145 epsilon: 0.2364391 step 1000 learning rate: 0.00025\n",
      "episode: 861 agent1 cumulative reward:  119 epsilon: 0.23581270000000001 step 696 learning rate: 0.00025\n",
      "episode: 862 agent1 cumulative reward:  122 epsilon: 0.23491270000000003 step 1000 learning rate: 0.00025\n",
      "episode: 863 agent1 cumulative reward:  119 epsilon: 0.23401270000000002 step 1000 learning rate: 0.00025\n",
      "episode: 864 agent1 cumulative reward:  99 epsilon: 0.23311720000000002 step 995 learning rate: 0.00025\n",
      "episode: 865 agent1 cumulative reward:  138 epsilon: 0.2322874 step 922 learning rate: 0.00025\n",
      "episode: 866 agent1 cumulative reward:  136 epsilon: 0.23160880000000003 step 754 learning rate: 0.00025\n",
      "episode: 867 agent1 cumulative reward:  126 epsilon: 0.2309023 step 785 learning rate: 0.00025\n",
      "episode: 868 agent1 cumulative reward:  139 epsilon: 0.2301922 step 789 learning rate: 0.00025\n",
      "episode: 869 agent1 cumulative reward:  152 epsilon: 0.2292922 step 1000 learning rate: 0.00025\n",
      "episode: 870 agent1 cumulative reward:  86 epsilon: 0.22888090000000003 step 457 learning rate: 0.00025\n",
      "episode: 871 agent1 cumulative reward:  113 epsilon: 0.22819150000000002 step 766 learning rate: 0.00025\n",
      "episode: 872 agent1 cumulative reward:  137 epsilon: 0.2272915 step 1000 learning rate: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 873 agent1 cumulative reward:  107 epsilon: 0.2263915 step 1000 learning rate: 0.00025\n",
      "episode: 874 agent1 cumulative reward:  146 epsilon: 0.2254915 step 1000 learning rate: 0.00025\n",
      "episode: 875 agent1 cumulative reward:  132 epsilon: 0.2245915 step 1000 learning rate: 0.00025\n",
      "episode: 876 agent1 cumulative reward:  154 epsilon: 0.2236915 step 1000 learning rate: 0.00025\n",
      "episode: 877 agent1 cumulative reward:  151 epsilon: 0.2227915 step 1000 learning rate: 0.00025\n",
      "episode: 878 agent1 cumulative reward:  156 epsilon: 0.22189150000000002 step 1000 learning rate: 0.00025\n",
      "episode: 879 agent1 cumulative reward:  194 epsilon: 0.2209915 step 1000 learning rate: 0.00025\n",
      "episode: 880 agent1 cumulative reward:  136 epsilon: 0.2200915 step 1000 learning rate: 0.00025\n",
      "episode: 881 agent1 cumulative reward:  182 epsilon: 0.2192095 step 980 learning rate: 0.00025\n",
      "episode: 882 agent1 cumulative reward:  139 epsilon: 0.2183095 step 1000 learning rate: 0.00025\n",
      "episode: 883 agent1 cumulative reward:  204 epsilon: 0.2174095 step 1000 learning rate: 0.00025\n",
      "episode: 884 agent1 cumulative reward:  162 epsilon: 0.21650950000000002 step 1000 learning rate: 0.00025\n",
      "episode: 885 agent1 cumulative reward:  131 epsilon: 0.2156095 step 1000 learning rate: 0.00025\n",
      "episode: 886 agent1 cumulative reward:  229 epsilon: 0.2147095 step 1000 learning rate: 0.00025\n",
      "episode: 887 agent1 cumulative reward:  131 epsilon: 0.21380949999999999 step 1000 learning rate: 0.00025\n",
      "episode: 888 agent1 cumulative reward:  226 epsilon: 0.2129095 step 1000 learning rate: 0.00025\n",
      "episode: 889 agent1 cumulative reward:  85 epsilon: 0.21200950000000002 step 1000 learning rate: 0.00025\n",
      "episode: 890 agent1 cumulative reward:  197 epsilon: 0.2111095 step 1000 learning rate: 0.00025\n",
      "episode: 891 agent1 cumulative reward:  102 epsilon: 0.2102095 step 1000 learning rate: 0.00025\n",
      "episode: 892 agent1 cumulative reward:  167 epsilon: 0.2093095 step 1000 learning rate: 0.00025\n",
      "episode: 893 agent1 cumulative reward:  155 epsilon: 0.20840950000000003 step 1000 learning rate: 0.00025\n",
      "episode: 894 agent1 cumulative reward:  143 epsilon: 0.2075095 step 1000 learning rate: 0.00025\n",
      "episode: 895 agent1 cumulative reward:  124 epsilon: 0.2066095 step 1000 learning rate: 0.00025\n",
      "episode: 896 agent1 cumulative reward:  142 epsilon: 0.2057095 step 1000 learning rate: 0.00025\n",
      "episode: 897 agent1 cumulative reward:  154 epsilon: 0.2048095 step 1000 learning rate: 0.00025\n"
     ]
    }
   ],
   "source": [
    "state_size = observation_space.shape[0]\n",
    "last_rewards=[]\n",
    "episode = 0\n",
    "max_episode_len = 1000\n",
    "gameovers = 0\n",
    "while episode < 2100:\n",
    "    episode += 1\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    total_reward = 0\n",
    "    \n",
    "    step=0\n",
    "    gameover = False\n",
    "    while not gameover:\n",
    "        step += 1\n",
    "        action = agent.get_action(state)\n",
    "        reward, next_state, done = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        total_reward += reward\n",
    "        agent.train_model(action, state, next_state, reward, done)\n",
    "        agent.update_epsilon()\n",
    "        state = next_state\n",
    "        terminal = (step >= max_episode_len)\n",
    "        if done or terminal:\n",
    "            gameovers += 1\n",
    "            last_rewards.append(total_reward)\n",
    "            agent.update_target_model()\n",
    "            gameover = True\n",
    "            \n",
    "    print('episode:', episode, 'agent1 cumulative reward: ', total_reward, 'epsilon:', agent.epsilon, 'step', step,\n",
    "             'learning rate:', agent.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 gameovers: 1\n",
      "1000 agent1 cumulative reward:  81\n",
      "1000 gameovers: 2\n",
      "1000 agent1 cumulative reward:  61\n",
      "1000 gameovers: 3\n",
      "1000 agent1 cumulative reward:  60\n",
      "1000 gameovers: 4\n",
      "1000 agent1 cumulative reward:  26\n",
      "1000 gameovers: 5\n",
      "1000 agent1 cumulative reward:  74\n",
      "1000 gameovers: 6\n",
      "1000 agent1 cumulative reward:  69\n",
      "1000 gameovers: 7\n",
      "1000 agent1 cumulative reward:  72\n",
      "1000 gameovers: 8\n",
      "1000 agent1 cumulative reward:  57\n",
      "1000 gameovers: 9\n",
      "1000 agent1 cumulative reward:  87\n",
      "1000 gameovers: 10\n",
      "1000 agent1 cumulative reward:  56\n",
      "1000 gameovers: 11\n",
      "1000 agent1 cumulative reward:  70\n",
      "1000 gameovers: 12\n",
      "1000 agent1 cumulative reward:  75\n",
      "1000 gameovers: 13\n",
      "1000 agent1 cumulative reward:  60\n",
      "1000 gameovers: 14\n",
      "1000 agent1 cumulative reward:  66\n",
      "1000 gameovers: 15\n",
      "1000 agent1 cumulative reward:  67\n",
      "1000 gameovers: 16\n",
      "1000 agent1 cumulative reward:  57\n",
      "1000 gameovers: 17\n",
      "1000 agent1 cumulative reward:  65\n",
      "1000 gameovers: 18\n",
      "1000 agent1 cumulative reward:  53\n",
      "1000 gameovers: 19\n",
      "1000 agent1 cumulative reward:  63\n",
      "1000 gameovers: 20\n",
      "1000 agent1 cumulative reward:  48\n",
      "1000 gameovers: 21\n",
      "1000 agent1 cumulative reward:  59\n",
      "1000 gameovers: 22\n",
      "1000 agent1 cumulative reward:  45\n",
      "1000 gameovers: 23\n",
      "1000 agent1 cumulative reward:  59\n",
      "1000 gameovers: 24\n",
      "1000 agent1 cumulative reward:  53\n",
      "1000 gameovers: 25\n",
      "1000 agent1 cumulative reward:  77\n",
      "1000 gameovers: 26\n",
      "1000 agent1 cumulative reward:  48\n",
      "1000 gameovers: 27\n",
      "1000 agent1 cumulative reward:  31\n",
      "1000 gameovers: 28\n",
      "1000 agent1 cumulative reward:  38\n",
      "1000 gameovers: 29\n",
      "1000 agent1 cumulative reward:  73\n",
      "1000 gameovers: 30\n",
      "1000 agent1 cumulative reward:  73\n",
      "1000 gameovers: 31\n",
      "1000 agent1 cumulative reward:  54\n",
      "1000 gameovers: 32\n",
      "1000 agent1 cumulative reward:  27\n",
      "1000 gameovers: 33\n",
      "1000 agent1 cumulative reward:  39\n",
      "1000 gameovers: 34\n",
      "1000 agent1 cumulative reward:  57\n",
      "1000 gameovers: 35\n",
      "1000 agent1 cumulative reward:  67\n",
      "1000 gameovers: 36\n",
      "1000 agent1 cumulative reward:  58\n",
      "1000 gameovers: 37\n",
      "1000 agent1 cumulative reward:  30\n",
      "1000 gameovers: 38\n",
      "1000 agent1 cumulative reward:  68\n",
      "1000 gameovers: 39\n",
      "1000 agent1 cumulative reward:  62\n",
      "1000 gameovers: 40\n",
      "1000 agent1 cumulative reward:  67\n",
      "1000 gameovers: 41\n",
      "1000 agent1 cumulative reward:  42\n",
      "1000 gameovers: 42\n",
      "1000 agent1 cumulative reward:  58\n",
      "1000 gameovers: 43\n",
      "1000 agent1 cumulative reward:  70\n",
      "1000 gameovers: 44\n",
      "1000 agent1 cumulative reward:  58\n",
      "1000 gameovers: 45\n",
      "1000 agent1 cumulative reward:  78\n",
      "1000 gameovers: 46\n",
      "1000 agent1 cumulative reward:  59\n",
      "1000 gameovers: 47\n",
      "1000 agent1 cumulative reward:  67\n",
      "1000 gameovers: 48\n",
      "1000 agent1 cumulative reward:  46\n",
      "1000 gameovers: 49\n",
      "1000 agent1 cumulative reward:  45\n",
      "1000 gameovers: 50\n",
      "1000 agent1 cumulative reward:  82\n",
      "1000 gameovers: 51\n",
      "1000 agent1 cumulative reward:  74\n",
      "1000 gameovers: 52\n",
      "1000 agent1 cumulative reward:  51\n",
      "1000 gameovers: 53\n",
      "1000 agent1 cumulative reward:  73\n",
      "1000 gameovers: 54\n",
      "1000 agent1 cumulative reward:  80\n",
      "1000 gameovers: 55\n",
      "1000 agent1 cumulative reward:  69\n",
      "1000 gameovers: 56\n",
      "1000 agent1 cumulative reward:  50\n",
      "1000 gameovers: 57\n",
      "1000 agent1 cumulative reward:  59\n",
      "1000 gameovers: 58\n",
      "1000 agent1 cumulative reward:  65\n",
      "1000 gameovers: 59\n",
      "1000 agent1 cumulative reward:  72\n",
      "1000 gameovers: 60\n",
      "1000 agent1 cumulative reward:  60\n",
      "1000 gameovers: 61\n",
      "1000 agent1 cumulative reward:  62\n",
      "1000 gameovers: 62\n",
      "1000 agent1 cumulative reward:  67\n",
      "1000 gameovers: 63\n",
      "1000 agent1 cumulative reward:  63\n",
      "1000 gameovers: 64\n",
      "1000 agent1 cumulative reward:  85\n",
      "1000 gameovers: 65\n",
      "1000 agent1 cumulative reward:  64\n",
      "1000 gameovers: 66\n",
      "1000 agent1 cumulative reward:  59\n",
      "1000 gameovers: 67\n",
      "1000 agent1 cumulative reward:  40\n",
      "1000 gameovers: 68\n",
      "1000 agent1 cumulative reward:  52\n",
      "1000 gameovers: 69\n",
      "1000 agent1 cumulative reward:  48\n",
      "1000 gameovers: 70\n",
      "1000 agent1 cumulative reward:  65\n",
      "1000 gameovers: 71\n",
      "1000 agent1 cumulative reward:  52\n",
      "1000 gameovers: 72\n",
      "1000 agent1 cumulative reward:  47\n",
      "1000 gameovers: 73\n",
      "1000 agent1 cumulative reward:  62\n",
      "1000 gameovers: 74\n",
      "1000 agent1 cumulative reward:  62\n",
      "1000 gameovers: 75\n",
      "1000 agent1 cumulative reward:  75\n",
      "1000 gameovers: 76\n",
      "1000 agent1 cumulative reward:  56\n",
      "1000 gameovers: 77\n",
      "1000 agent1 cumulative reward:  64\n",
      "1000 gameovers: 78\n",
      "1000 agent1 cumulative reward:  82\n",
      "1000 gameovers: 79\n",
      "1000 agent1 cumulative reward:  68\n",
      "1000 gameovers: 80\n",
      "1000 agent1 cumulative reward:  59\n",
      "1000 gameovers: 81\n",
      "1000 agent1 cumulative reward:  79\n",
      "1000 gameovers: 82\n",
      "1000 agent1 cumulative reward:  52\n",
      "1000 gameovers: 83\n",
      "1000 agent1 cumulative reward:  32\n",
      "1000 gameovers: 84\n",
      "1000 agent1 cumulative reward:  58\n",
      "1000 gameovers: 85\n",
      "1000 agent1 cumulative reward:  63\n",
      "1000 gameovers: 86\n",
      "1000 agent1 cumulative reward:  58\n",
      "1000 gameovers: 87\n",
      "1000 agent1 cumulative reward:  44\n",
      "1000 gameovers: 88\n",
      "1000 agent1 cumulative reward:  60\n",
      "1000 gameovers: 89\n",
      "1000 agent1 cumulative reward:  64\n",
      "1000 gameovers: 90\n",
      "1000 agent1 cumulative reward:  49\n",
      "1000 gameovers: 91\n",
      "1000 agent1 cumulative reward:  67\n",
      "1000 gameovers: 92\n",
      "1000 agent1 cumulative reward:  47\n",
      "1000 gameovers: 93\n",
      "1000 agent1 cumulative reward:  59\n",
      "1000 gameovers: 94\n",
      "1000 agent1 cumulative reward:  32\n",
      "1000 gameovers: 95\n",
      "1000 agent1 cumulative reward:  67\n",
      "1000 gameovers: 96\n",
      "1000 agent1 cumulative reward:  68\n",
      "1000 gameovers: 97\n",
      "1000 agent1 cumulative reward:  62\n",
      "1000 gameovers: 98\n",
      "1000 agent1 cumulative reward:  30\n",
      "1000 gameovers: 99\n",
      "1000 agent1 cumulative reward:  61\n",
      "1000 gameovers: 100\n",
      "1000 agent1 cumulative reward:  46\n"
     ]
    }
   ],
   "source": [
    "episode = 0\n",
    "max_episode_len = 1000\n",
    "gameovers = 0\n",
    "\n",
    "while episode < 100:\n",
    "    env = GameEnv()\n",
    "    episode += 1\n",
    "    obs_n = env.reset()\n",
    "    #env.render_env()\n",
    "\n",
    "    agent1_reward = 0\n",
    "\n",
    "    step = 0\n",
    "    gameover = False\n",
    "    while not gameover:\n",
    "        step += 1\n",
    "        #env.render_env()\n",
    "\n",
    "        # take a random action\n",
    "        action_n = np.random.randint(7)\n",
    "        #action_n = [action1, action2, action3]\n",
    "\n",
    "        rew_n, new_obs_n, done = env.step(action_n)\n",
    "\n",
    "\n",
    "        agent1_reward += rew_n\n",
    "\n",
    "        terminal = (step >= max_episode_len)\n",
    "\n",
    "        if done or terminal:\n",
    "            gameovers += 1\n",
    "            print(step, 'gameovers:', gameovers)\n",
    "            gameover = True  # gameover for everyone, called when all apples are collected\n",
    "\n",
    "        #for i, agent in enumerate(trainers):\n",
    "         #   agent.experience(obs_n[i], action_n[i], rew_n[i], new_obs_n[i], done_n[i], terminal)\n",
    "\n",
    "        obs_n = new_obs_n\n",
    "\n",
    "    print(step, 'agent1 cumulative reward: ', agent1_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
